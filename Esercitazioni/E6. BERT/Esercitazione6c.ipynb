{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "o_9x1m3YC3RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893fd00b-aec6-4c92-b70f-6845e6c7a54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5jGMRPJ1E1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceeec5e9-b7f3-4980-923e-245a5a0ab2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Dataset\n",
        "# repository https://github.com/iresiragusa/NLP/tree/main\n",
        "# https://www.kaggle.com/datasets/yufengdev/bbc-fulltext-and-category?select=bbc-text.csv\n",
        "# scarichiamo il dataset e lo carichiamo su COLAB\n",
        "\n",
        "root = \"/content/gdrive/MyDrive/Colab Notebooks/torch/\"\n",
        "df = pd.read_csv(root+\"data/BBC-text/bbc-text.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# associo ad ogni categoria un indice, così ho delle label numeriche\n",
        "labels_dict = {\n",
        "    'business': 0,\n",
        "    'politics': 1,\n",
        "    'tech': 2,\n",
        "    'sport': 3,\n",
        "    'entertainment': 4\n",
        "}\n",
        "\n",
        "id_labels_dict = {\n",
        "    0: 'business',\n",
        "    1 : 'politics',\n",
        "    2 : 'tech',\n",
        "    3 : 'sport',\n",
        "    4: 'entertainment'\n",
        "}\n",
        "\n",
        "df['labels'] = df.apply(lambda row: labels_dict[row.category], axis = 1)"
      ],
      "metadata": {
        "id": "ystNFP_lfgwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, x_test, y_train, y_test) = train_test_split(df['text'], df['labels'], test_size=0.2, random_state=17)\n",
        "\n",
        "(x_train, x_val, y_train, y_val) = train_test_split( x_train, y_train, test_size=0.1, random_state=17)"
      ],
      "metadata": {
        "id": "s16PrHdD1bs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    \"epochs\": 5,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 16,\n",
        "    \"dropout\": 0.1,\n",
        "    #\"stopwords\": True,\n",
        "    \"stopwords\": False,\n",
        "    \"h_dim\": 768,\n",
        "    \"patience\": 5,\n",
        "    \"min_delta\": 0.01,\n",
        "    \"language_model\": \"bert-base-uncased\"\n",
        "}"
      ],
      "metadata": {
        "id": "TdXojbqsejFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, y, stopwords):\n",
        "\n",
        "        if stopwords:\n",
        "            tokens_litt = [nltk.word_tokenize(text, language='english') for text in list(x)]\n",
        "            text_clean = []\n",
        "            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n",
        "                text_clean.append(' '.join([w for w in sentence if not w.lower() in nltk.corpus.stopwords.words(\"english\")]))\n",
        "        else:\n",
        "            tokens_litt = [nltk.word_tokenize(text, language='english') for text in list(x)]\n",
        "            text_clean = []\n",
        "            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n",
        "                #sentence_clean = ' '.join([w.lower() for w in sentence])\n",
        "                #text_clean.append(sentence_clean)\n",
        "                text_clean.append(' '.join([w.lower() for w in sentence]))\n",
        "            # ogni token è separato dall'altro con uno spazio\n",
        "        self.texts = [text for text in text_clean]\n",
        "        self.labels = [torch.tensor(label) for label in y]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_labels"
      ],
      "metadata": {
        "id": "WlYWKSjDeQi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573f3bd3-2fa7-4b73-d20a-17b1b1dac5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creo i dataset\n",
        "\n",
        "train_dataset = Dataset(x_train, y_train, hyperparameters[\"stopwords\"])\n",
        "val_dataset = Dataset(x_val, y_val, hyperparameters[\"stopwords\"])\n",
        "test_dataset = Dataset(x_test, y_test, hyperparameters[\"stopwords\"])"
      ],
      "metadata": {
        "id": "WbuEU9Xzevlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e76b15-d9a4-4895-c9c6-cb842eb786f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing ... : 100%|██████████| 1602/1602 [00:00<00:00, 10470.16it/s]\n",
            "Tokenizing ... : 100%|██████████| 178/178 [00:00<00:00, 11079.90it/s]\n",
            "Tokenizing ... : 100%|██████████| 445/445 [00:00<00:00, 12229.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0):\n",
        "\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta              # valore minimo di decrescita della loss di validazione all'epoca corrente\n",
        "                                                # per asserire che c'è un miglioramenti della loss\n",
        "        self.counter = 0                        # contatore delle epoche di pazienza\n",
        "        self.early_stop = False                 # flag di early stop\n",
        "        self.min_validation_loss = torch.inf    # valore corrente ottimo della loss di validazione\n",
        "\n",
        "    def __call__(self, validation_loss):\n",
        "        # chiamata in forma funzionale dell'oggetto di classe EarlySopping\n",
        "\n",
        "        if (validation_loss + self.min_delta) >= self.min_validation_loss:  # la loss di validazione non decresce\n",
        "            self.counter += 1                                               # incrementiamo il contatore delle epoche di pazienza\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                print(\"Early stop!\")\n",
        "        else:                                                               # c'è un miglioramento della loss:\n",
        "            self.min_validation_loss = validation_loss                      # consideriamo la loss corrente\n",
        "                                                                            # come nuova loss ottimale\n",
        "            self.counter = 0                                                # e azzeriamo il contatore di pazienza"
      ],
      "metadata": {
        "id": "YeLXqnCIgc9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invece di una rete scritta da noi, useremo un modello di huggingface per text classification.\n",
        "\n",
        "Ogni modello/tokenizer può essere richiamato con la sua classe o tramite la autoclass, che automaticamente instanzia l'oggetto corrispondente al nome del modello:\n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") #(1)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "Dalla documentazione (https://huggingface.co/docs/transformers/index) potete vedere tutte le classi e i modelli disponibili. Per il caricamento di un modello via autoclass di cui conoscete il nome ma non l'esatta dicitura, per inserirla in (1), cercatlo su huggingface, da qua (https://huggingface.co/) inserendo il nome e si aprirà la scheda del modello con il nome per il caricamento sul codice python, con descrizione e codice di esempio (vedi RoBERTa il cui nome del modello da inserire nel codice è roberta-base https://huggingface.co/roberta-base)"
      ],
      "metadata": {
        "id": "72te7LcobYFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, dataloader, tokenizer, loss, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch_texts, batch_labels in tqdm(dataloader, desc='training set'):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        tokens = tokenizer(list(batch_texts), add_special_tokens=True, return_tensors='pt', padding='max_length', max_length = 512, truncation=True)\n",
        "        input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n",
        "        mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        output = model(input_id_texts, mask_texts).logits # .logits permette di prendere l'output desiderato dal modello\n",
        "\n",
        "        # la loss è una CrossEntropyLoss, al suo interno ha la logsoftmax + negative log likelihood loss\n",
        "        batch_loss = loss(output, batch_labels)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += batch_loss.item()\n",
        "\n",
        "        # per calcolare l'accuracy devo generare le predizioni applicando manualmente la logsoftmax\n",
        "        softmax = nn.LogSoftmax(dim=1)\n",
        "        epoch_acc += (softmax(output).argmax(dim=1) == batch_labels).sum().item()\n",
        "\n",
        "        batch_labels = batch_labels.detach().cpu()\n",
        "        input_id_texts = input_id_texts.detach().cpu()\n",
        "        mask_texts = mask_texts.detach().cpu()\n",
        "        output = output.detach().cpu()\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc"
      ],
      "metadata": {
        "id": "eRwTy5yVgoCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model, dataloader, tokenizer, loss, device):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_texts, batch_labels, in tqdm(dataloader, desc='dev set'):\n",
        "\n",
        "            tokens = tokenizer(list(batch_texts), add_special_tokens=True, return_tensors='pt', padding='max_length', max_length = 512, truncation=True)\n",
        "            input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n",
        "            mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            output = model(input_id_texts, mask_texts).logits\n",
        "\n",
        "            batch_loss = loss(output, batch_labels)\n",
        "            epoch_loss += batch_loss.item()\n",
        "\n",
        "            softmax = nn.LogSoftmax(dim=1)\n",
        "            epoch_acc += (softmax(output).argmax(dim=1) == batch_labels).sum().item()\n",
        "\n",
        "            batch_labels = batch_labels.detach().cpu()\n",
        "            input_id_texts = input_id_texts.detach().cpu()\n",
        "            mask_texts = mask_texts.detach().cpu()\n",
        "            output = output.detach().cpu()\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc"
      ],
      "metadata": {
        "id": "Jo7jZ2PDuRAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(model, epochs, optimizer, device, train_data, test_data,\n",
        "               batch_size, language_model, train_loss_fn, test_loss_fn=None,\n",
        "               early_stopping=None, val_data=None, scheduler=None):\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    # check sulle funzioni di loss\n",
        "    if test_loss_fn == None:\n",
        "        test_loss_fn = train_loss_fn\n",
        "\n",
        "    # liste dei valori di loss e accuracy epoca per epoca per il plot\n",
        "    train_loss = []\n",
        "    validation_loss = []\n",
        "    test_loss = []\n",
        "\n",
        "    train_acc = []\n",
        "    validation_acc = []\n",
        "    test_acc = []\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(language_model)\n",
        "\n",
        "    # Ciclo di addestramento con early stopping\n",
        "    for epoch in tqdm(range(1,epochs+1)):\n",
        "\n",
        "        epoch_train_loss, epoch_train_acc = train_loop(model, train_dataloader, tokenizer, train_loss_fn, optimizer, device)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc/len(train_data))\n",
        "\n",
        "        # validation se è presente la callback di early stopping\n",
        "        if early_stopping != None:\n",
        "                epoch_validate_loss, epoch_validate_acc = test_loop(model, val_dataloader, tokenizer, test_loss_fn, device)\n",
        "                validation_loss.append(epoch_validate_loss)\n",
        "                validation_acc.append(epoch_validate_acc/len(val_data))\n",
        "\n",
        "        # test\n",
        "        epoch_test_loss, epoch_test_acc,= test_loop(model, test_dataloader, tokenizer, test_loss_fn, device)\n",
        "        test_loss.append(epoch_test_loss)\n",
        "        test_acc.append(epoch_test_acc/len(test_data))\n",
        "\n",
        "        val_loss_str = f'Validation loss: {epoch_validate_loss:6.4f} ' if early_stopping != None else ' '\n",
        "        val_acc_str = f'Validation accuracy: {(epoch_validate_acc/len(val_data)):6.4f} ' if early_stopping != None else ' '\n",
        "        print(f\"\\nTrain loss: {epoch_train_loss:6.4f} {val_loss_str}Test loss: {epoch_test_loss:6.4f}\")\n",
        "        print(f\"Train accuracy: {(epoch_train_acc/len(train_data)):6.4f} {val_acc_str}Test accuracy: {(epoch_test_acc/len(test_data)):6.4f}\")\n",
        "\n",
        "        # early stopping\n",
        "        if early_stopping != None:\n",
        "                early_stopping(epoch_validate_loss)\n",
        "                if early_stopping.early_stop:\n",
        "                    break\n",
        "\n",
        "    return train_loss, validation_loss, test_loss, train_acc, validation_acc, test_acc"
      ],
      "metadata": {
        "id": "W_urLi5MubL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acquisiamo il device su cui effettueremo il training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "''' model = ClassifierDeep(len(labels_dict),\n",
        "                    hyperparameters[\"h_dim\"],\n",
        "                    hyperparameters[\"dropout\"],\n",
        "                    ).to(device) '''\n",
        "\n",
        "\n",
        "model_name = hyperparameters[\"language_model\"]  # You can change this to any other supported model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(labels_dict)).to(device)\n",
        "print(model)\n",
        "\n",
        "# Calcoliamo il numero totale dei parametri del modello\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Numbero totale dei parametri: {total_params}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"])\n",
        "\n",
        "# Creiamo la callback di early stopping da passare al nostro metodo di addestramento\n",
        "early_stopping = EarlyStopping(patience=hyperparameters['patience'],\n",
        "                               min_delta=hyperparameters['min_delta'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozVTHJGFvjEi",
        "outputId": "1d71aae1-d533-455f-db0a-e95bc0425075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
            ")\n",
            "Numbero totale dei parametri: 109486085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Routine di addestramento\n",
        "train_loss, validation_loss,test_loss, train_acc, validation_acc, test_acc = train_test(model,\n",
        "                                                hyperparameters['epochs'],\n",
        "                                                #50,\n",
        "                                                optimizer,\n",
        "                                                device,\n",
        "                                                train_dataset,\n",
        "                                                test_dataset,\n",
        "                                                hyperparameters['batch_size'],\n",
        "                                                hyperparameters['language_model'],\n",
        "                                                criterion,\n",
        "                                                criterion,\n",
        "                                                early_stopping,\n",
        "                                                val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHT4iHdawXrT",
        "outputId": "2e12add5-9d6f-4f0e-d48a-707302bb6d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "training set:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   1%|          | 1/101 [00:01<02:33,  1.53s/it]\u001b[A\n",
            "training set:   2%|▏         | 2/101 [00:03<02:28,  1.50s/it]\u001b[A\n",
            "training set:   3%|▎         | 3/101 [00:04<02:26,  1.50s/it]\u001b[A\n",
            "training set:   4%|▍         | 4/101 [00:06<02:25,  1.50s/it]\u001b[A\n",
            "training set:   5%|▍         | 5/101 [00:07<02:23,  1.49s/it]\u001b[A\n",
            "training set:   6%|▌         | 6/101 [00:08<02:22,  1.50s/it]\u001b[A\n",
            "training set:   7%|▋         | 7/101 [00:10<02:21,  1.50s/it]\u001b[A\n",
            "training set:   8%|▊         | 8/101 [00:12<02:20,  1.51s/it]\u001b[A\n",
            "training set:   9%|▉         | 9/101 [00:13<02:19,  1.52s/it]\u001b[A\n",
            "training set:  10%|▉         | 10/101 [00:15<02:18,  1.52s/it]\u001b[A\n",
            "training set:  11%|█         | 11/101 [00:16<02:16,  1.52s/it]\u001b[A\n",
            "training set:  12%|█▏        | 12/101 [00:18<02:14,  1.52s/it]\u001b[A\n",
            "training set:  13%|█▎        | 13/101 [00:19<02:13,  1.52s/it]\u001b[A\n",
            "training set:  14%|█▍        | 14/101 [00:21<02:11,  1.51s/it]\u001b[A\n",
            "training set:  15%|█▍        | 15/101 [00:22<02:10,  1.52s/it]\u001b[A\n",
            "training set:  16%|█▌        | 16/101 [00:24<02:09,  1.52s/it]\u001b[A\n",
            "training set:  17%|█▋        | 17/101 [00:25<02:08,  1.53s/it]\u001b[A\n",
            "training set:  18%|█▊        | 18/101 [00:27<02:07,  1.53s/it]\u001b[A\n",
            "training set:  19%|█▉        | 19/101 [00:28<02:06,  1.54s/it]\u001b[A\n",
            "training set:  20%|█▉        | 20/101 [00:30<02:04,  1.54s/it]\u001b[A\n",
            "training set:  21%|██        | 21/101 [00:31<02:03,  1.54s/it]\u001b[A\n",
            "training set:  22%|██▏       | 22/101 [00:33<02:02,  1.55s/it]\u001b[A\n",
            "training set:  23%|██▎       | 23/101 [00:35<02:01,  1.55s/it]\u001b[A\n",
            "training set:  24%|██▍       | 24/101 [00:36<01:59,  1.55s/it]\u001b[A\n",
            "training set:  25%|██▍       | 25/101 [00:38<01:57,  1.54s/it]\u001b[A\n",
            "training set:  26%|██▌       | 26/101 [00:39<01:54,  1.53s/it]\u001b[A\n",
            "training set:  27%|██▋       | 27/101 [00:41<01:52,  1.52s/it]\u001b[A\n",
            "training set:  28%|██▊       | 28/101 [00:42<01:50,  1.52s/it]\u001b[A\n",
            "training set:  29%|██▊       | 29/101 [00:44<01:49,  1.52s/it]\u001b[A\n",
            "training set:  30%|██▉       | 30/101 [00:45<01:47,  1.51s/it]\u001b[A\n",
            "training set:  31%|███       | 31/101 [00:47<01:46,  1.52s/it]\u001b[A\n",
            "training set:  32%|███▏      | 32/101 [00:48<01:44,  1.52s/it]\u001b[A\n",
            "training set:  33%|███▎      | 33/101 [00:50<01:43,  1.52s/it]\u001b[A\n",
            "training set:  34%|███▎      | 34/101 [00:51<01:41,  1.52s/it]\u001b[A\n",
            "training set:  35%|███▍      | 35/101 [00:53<01:40,  1.52s/it]\u001b[A\n",
            "training set:  36%|███▌      | 36/101 [00:54<01:38,  1.51s/it]\u001b[A\n",
            "training set:  37%|███▋      | 37/101 [00:56<01:36,  1.51s/it]\u001b[A\n",
            "training set:  38%|███▊      | 38/101 [00:57<01:35,  1.51s/it]\u001b[A\n",
            "training set:  39%|███▊      | 39/101 [00:59<01:33,  1.50s/it]\u001b[A\n",
            "training set:  40%|███▉      | 40/101 [01:00<01:31,  1.50s/it]\u001b[A\n",
            "training set:  41%|████      | 41/101 [01:02<01:29,  1.49s/it]\u001b[A\n",
            "training set:  42%|████▏     | 42/101 [01:03<01:27,  1.49s/it]\u001b[A\n",
            "training set:  43%|████▎     | 43/101 [01:05<01:26,  1.50s/it]\u001b[A\n",
            "training set:  44%|████▎     | 44/101 [01:06<01:25,  1.51s/it]\u001b[A\n",
            "training set:  45%|████▍     | 45/101 [01:08<01:23,  1.50s/it]\u001b[A\n",
            "training set:  46%|████▌     | 46/101 [01:09<01:22,  1.50s/it]\u001b[A\n",
            "training set:  47%|████▋     | 47/101 [01:11<01:20,  1.50s/it]\u001b[A\n",
            "training set:  48%|████▊     | 48/101 [01:12<01:19,  1.50s/it]\u001b[A\n",
            "training set:  49%|████▊     | 49/101 [01:14<01:18,  1.51s/it]\u001b[A\n",
            "training set:  50%|████▉     | 50/101 [01:15<01:18,  1.53s/it]\u001b[A\n",
            "training set:  50%|█████     | 51/101 [01:17<01:15,  1.51s/it]\u001b[A\n",
            "training set:  51%|█████▏    | 52/101 [01:18<01:13,  1.51s/it]\u001b[A\n",
            "training set:  52%|█████▏    | 53/101 [01:20<01:11,  1.50s/it]\u001b[A\n",
            "training set:  53%|█████▎    | 54/101 [01:21<01:10,  1.49s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 55/101 [01:23<01:08,  1.49s/it]\u001b[A\n",
            "training set:  55%|█████▌    | 56/101 [01:24<01:07,  1.49s/it]\u001b[A\n",
            "training set:  56%|█████▋    | 57/101 [01:26<01:05,  1.49s/it]\u001b[A\n",
            "training set:  57%|█████▋    | 58/101 [01:27<01:04,  1.49s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 59/101 [01:29<01:03,  1.50s/it]\u001b[A\n",
            "training set:  59%|█████▉    | 60/101 [01:30<01:02,  1.52s/it]\u001b[A\n",
            "training set:  60%|██████    | 61/101 [01:32<01:00,  1.51s/it]\u001b[A\n",
            "training set:  61%|██████▏   | 62/101 [01:33<00:58,  1.51s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 63/101 [01:35<00:57,  1.51s/it]\u001b[A\n",
            "training set:  63%|██████▎   | 64/101 [01:36<00:55,  1.51s/it]\u001b[A\n",
            "training set:  64%|██████▍   | 65/101 [01:38<00:54,  1.50s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 66/101 [01:39<00:52,  1.50s/it]\u001b[A\n",
            "training set:  66%|██████▋   | 67/101 [01:41<00:50,  1.49s/it]\u001b[A\n",
            "training set:  67%|██████▋   | 68/101 [01:42<00:49,  1.49s/it]\u001b[A\n",
            "training set:  68%|██████▊   | 69/101 [01:44<00:47,  1.49s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 70/101 [01:45<00:46,  1.50s/it]\u001b[A\n",
            "training set:  70%|███████   | 71/101 [01:47<00:45,  1.50s/it]\u001b[A\n",
            "training set:  71%|███████▏  | 72/101 [01:48<00:43,  1.51s/it]\u001b[A\n",
            "training set:  72%|███████▏  | 73/101 [01:50<00:42,  1.51s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 74/101 [01:51<00:40,  1.52s/it]\u001b[A\n",
            "training set:  74%|███████▍  | 75/101 [01:53<00:39,  1.52s/it]\u001b[A\n",
            "training set:  75%|███████▌  | 76/101 [01:54<00:38,  1.53s/it]\u001b[A\n",
            "training set:  76%|███████▌  | 77/101 [01:56<00:36,  1.53s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 78/101 [01:57<00:34,  1.52s/it]\u001b[A\n",
            "training set:  78%|███████▊  | 79/101 [01:59<00:33,  1.52s/it]\u001b[A\n",
            "training set:  79%|███████▉  | 80/101 [02:00<00:31,  1.51s/it]\u001b[A\n",
            "training set:  80%|████████  | 81/101 [02:02<00:30,  1.51s/it]\u001b[A\n",
            "training set:  81%|████████  | 82/101 [02:03<00:28,  1.51s/it]\u001b[A\n",
            "training set:  82%|████████▏ | 83/101 [02:05<00:27,  1.51s/it]\u001b[A\n",
            "training set:  83%|████████▎ | 84/101 [02:07<00:25,  1.52s/it]\u001b[A\n",
            "training set:  84%|████████▍ | 85/101 [02:08<00:24,  1.53s/it]\u001b[A\n",
            "training set:  85%|████████▌ | 86/101 [02:10<00:22,  1.52s/it]\u001b[A\n",
            "training set:  86%|████████▌ | 87/101 [02:11<00:21,  1.52s/it]\u001b[A\n",
            "training set:  87%|████████▋ | 88/101 [02:13<00:19,  1.52s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 89/101 [02:14<00:18,  1.53s/it]\u001b[A\n",
            "training set:  89%|████████▉ | 90/101 [02:16<00:16,  1.53s/it]\u001b[A\n",
            "training set:  90%|█████████ | 91/101 [02:17<00:15,  1.52s/it]\u001b[A\n",
            "training set:  91%|█████████ | 92/101 [02:19<00:13,  1.51s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 93/101 [02:20<00:12,  1.51s/it]\u001b[A\n",
            "training set:  93%|█████████▎| 94/101 [02:22<00:10,  1.51s/it]\u001b[A\n",
            "training set:  94%|█████████▍| 95/101 [02:23<00:09,  1.50s/it]\u001b[A\n",
            "training set:  95%|█████████▌| 96/101 [02:25<00:07,  1.51s/it]\u001b[A\n",
            "training set:  96%|█████████▌| 97/101 [02:26<00:06,  1.51s/it]\u001b[A\n",
            "training set:  97%|█████████▋| 98/101 [02:28<00:04,  1.52s/it]\u001b[A\n",
            "training set:  98%|█████████▊| 99/101 [02:29<00:03,  1.52s/it]\u001b[A\n",
            "training set:  99%|█████████▉| 100/101 [02:31<00:01,  1.52s/it]\u001b[A\n",
            "training set: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n",
            "\n",
            "dev set:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   8%|▊         | 1/12 [00:00<00:05,  1.92it/s]\u001b[A\n",
            "dev set:  17%|█▋        | 2/12 [00:01<00:05,  1.89it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 3/12 [00:01<00:04,  1.88it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 4/12 [00:02<00:04,  1.88it/s]\u001b[A\n",
            "dev set:  42%|████▏     | 5/12 [00:02<00:03,  1.89it/s]\u001b[A\n",
            "dev set:  50%|█████     | 6/12 [00:03<00:03,  1.88it/s]\u001b[A\n",
            "dev set:  58%|█████▊    | 7/12 [00:03<00:02,  1.89it/s]\u001b[A\n",
            "dev set:  67%|██████▋   | 8/12 [00:04<00:02,  1.90it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 9/12 [00:04<00:01,  1.92it/s]\u001b[A\n",
            "dev set:  83%|████████▎ | 10/12 [00:05<00:01,  1.92it/s]\u001b[A\n",
            "dev set: 100%|██████████| 12/12 [00:05<00:00,  2.05it/s]\n",
            "\n",
            "dev set:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   4%|▎         | 1/28 [00:00<00:13,  1.96it/s]\u001b[A\n",
            "dev set:   7%|▋         | 2/28 [00:01<00:13,  1.95it/s]\u001b[A\n",
            "dev set:  11%|█         | 3/28 [00:01<00:12,  1.94it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 4/28 [00:02<00:12,  1.95it/s]\u001b[A\n",
            "dev set:  18%|█▊        | 5/28 [00:02<00:11,  1.93it/s]\u001b[A\n",
            "dev set:  21%|██▏       | 6/28 [00:03<00:11,  1.94it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 7/28 [00:03<00:10,  1.93it/s]\u001b[A\n",
            "dev set:  29%|██▊       | 8/28 [00:04<00:10,  1.92it/s]\u001b[A\n",
            "dev set:  32%|███▏      | 9/28 [00:04<00:09,  1.93it/s]\u001b[A\n",
            "dev set:  36%|███▌      | 10/28 [00:05<00:09,  1.94it/s]\u001b[A\n",
            "dev set:  39%|███▉      | 11/28 [00:05<00:08,  1.93it/s]\u001b[A\n",
            "dev set:  43%|████▎     | 12/28 [00:06<00:08,  1.93it/s]\u001b[A\n",
            "dev set:  46%|████▋     | 13/28 [00:06<00:07,  1.93it/s]\u001b[A\n",
            "dev set:  50%|█████     | 14/28 [00:07<00:07,  1.93it/s]\u001b[A\n",
            "dev set:  54%|█████▎    | 15/28 [00:07<00:06,  1.90it/s]\u001b[A\n",
            "dev set:  57%|█████▋    | 16/28 [00:08<00:06,  1.89it/s]\u001b[A\n",
            "dev set:  61%|██████    | 17/28 [00:08<00:05,  1.89it/s]\u001b[A\n",
            "dev set:  64%|██████▍   | 18/28 [00:09<00:05,  1.88it/s]\u001b[A\n",
            "dev set:  68%|██████▊   | 19/28 [00:09<00:04,  1.89it/s]\u001b[A\n",
            "dev set:  71%|███████▏  | 20/28 [00:10<00:04,  1.89it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 21/28 [00:10<00:03,  1.90it/s]\u001b[A\n",
            "dev set:  79%|███████▊  | 22/28 [00:11<00:03,  1.90it/s]\u001b[A\n",
            "dev set:  82%|████████▏ | 23/28 [00:12<00:02,  1.90it/s]\u001b[A\n",
            "dev set:  86%|████████▌ | 24/28 [00:12<00:02,  1.89it/s]\u001b[A\n",
            "dev set:  89%|████████▉ | 25/28 [00:13<00:01,  1.86it/s]\u001b[A\n",
            "dev set:  93%|█████████▎| 26/28 [00:13<00:01,  1.85it/s]\u001b[A\n",
            "dev set:  96%|█████████▋| 27/28 [00:14<00:00,  1.83it/s]\u001b[A\n",
            "dev set: 100%|██████████| 28/28 [00:14<00:00,  1.91it/s]\n",
            " 20%|██        | 1/5 [02:52<11:28, 172.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 1.6988 Validation loss: 1.6547 Test loss: 1.6906\n",
            "Train accuracy: 0.1998 Validation accuracy: 0.1966 Test accuracy: 0.1663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   1%|          | 1/101 [00:01<02:31,  1.51s/it]\u001b[A\n",
            "training set:   2%|▏         | 2/101 [00:03<02:28,  1.50s/it]\u001b[A\n",
            "training set:   3%|▎         | 3/101 [00:04<02:26,  1.49s/it]\u001b[A\n",
            "training set:   4%|▍         | 4/101 [00:06<02:25,  1.50s/it]\u001b[A\n",
            "training set:   5%|▍         | 5/101 [00:07<02:23,  1.50s/it]\u001b[A\n",
            "training set:   6%|▌         | 6/101 [00:08<02:22,  1.50s/it]\u001b[A\n",
            "training set:   7%|▋         | 7/101 [00:10<02:20,  1.50s/it]\u001b[A\n",
            "training set:   8%|▊         | 8/101 [00:11<02:18,  1.49s/it]\u001b[A\n",
            "training set:   9%|▉         | 9/101 [00:13<02:17,  1.50s/it]\u001b[A\n",
            "training set:  10%|▉         | 10/101 [00:15<02:17,  1.51s/it]\u001b[A\n",
            "training set:  11%|█         | 11/101 [00:16<02:16,  1.52s/it]\u001b[A\n",
            "training set:  12%|█▏        | 12/101 [00:18<02:14,  1.52s/it]\u001b[A\n",
            "training set:  13%|█▎        | 13/101 [00:19<02:13,  1.52s/it]\u001b[A\n",
            "training set:  14%|█▍        | 14/101 [00:21<02:12,  1.52s/it]\u001b[A\n",
            "training set:  15%|█▍        | 15/101 [00:22<02:10,  1.52s/it]\u001b[A\n",
            "training set:  16%|█▌        | 16/101 [00:24<02:08,  1.51s/it]\u001b[A\n",
            "training set:  17%|█▋        | 17/101 [00:25<02:06,  1.51s/it]\u001b[A\n",
            "training set:  18%|█▊        | 18/101 [00:27<02:04,  1.50s/it]\u001b[A\n",
            "training set:  19%|█▉        | 19/101 [00:28<02:02,  1.50s/it]\u001b[A\n",
            "training set:  20%|█▉        | 20/101 [00:30<02:01,  1.50s/it]\u001b[A\n",
            "training set:  21%|██        | 21/101 [00:31<01:59,  1.49s/it]\u001b[A\n",
            "training set:  22%|██▏       | 22/101 [00:33<01:58,  1.49s/it]\u001b[A\n",
            "training set:  23%|██▎       | 23/101 [00:34<01:56,  1.50s/it]\u001b[A\n",
            "training set:  24%|██▍       | 24/101 [00:36<01:55,  1.50s/it]\u001b[A\n",
            "training set:  25%|██▍       | 25/101 [00:37<01:54,  1.50s/it]\u001b[A\n",
            "training set:  26%|██▌       | 26/101 [00:39<01:53,  1.52s/it]\u001b[A\n",
            "training set:  27%|██▋       | 27/101 [00:40<01:52,  1.52s/it]\u001b[A\n",
            "training set:  28%|██▊       | 28/101 [00:42<01:51,  1.52s/it]\u001b[A\n",
            "training set:  29%|██▊       | 29/101 [00:43<01:48,  1.51s/it]\u001b[A\n",
            "training set:  30%|██▉       | 30/101 [00:45<01:46,  1.51s/it]\u001b[A\n",
            "training set:  31%|███       | 31/101 [00:46<01:45,  1.51s/it]\u001b[A\n",
            "training set:  32%|███▏      | 32/101 [00:48<01:43,  1.50s/it]\u001b[A\n",
            "training set:  33%|███▎      | 33/101 [00:49<01:42,  1.50s/it]\u001b[A\n",
            "training set:  34%|███▎      | 34/101 [00:51<01:40,  1.50s/it]\u001b[A\n",
            "training set:  35%|███▍      | 35/101 [00:52<01:39,  1.51s/it]\u001b[A\n",
            "training set:  36%|███▌      | 36/101 [00:54<01:38,  1.52s/it]\u001b[A\n",
            "training set:  37%|███▋      | 37/101 [00:55<01:37,  1.52s/it]\u001b[A\n",
            "training set:  38%|███▊      | 38/101 [00:57<01:35,  1.51s/it]\u001b[A\n",
            "training set:  39%|███▊      | 39/101 [00:58<01:34,  1.52s/it]\u001b[A\n",
            "training set:  40%|███▉      | 40/101 [01:00<01:33,  1.53s/it]\u001b[A\n",
            "training set:  41%|████      | 41/101 [01:01<01:31,  1.52s/it]\u001b[A\n",
            "training set:  42%|████▏     | 42/101 [01:03<01:29,  1.51s/it]\u001b[A\n",
            "training set:  43%|████▎     | 43/101 [01:04<01:27,  1.51s/it]\u001b[A\n",
            "training set:  44%|████▎     | 44/101 [01:06<01:25,  1.50s/it]\u001b[A\n",
            "training set:  45%|████▍     | 45/101 [01:07<01:24,  1.50s/it]\u001b[A\n",
            "training set:  46%|████▌     | 46/101 [01:09<01:22,  1.50s/it]\u001b[A\n",
            "training set:  47%|████▋     | 47/101 [01:10<01:21,  1.50s/it]\u001b[A\n",
            "training set:  48%|████▊     | 48/101 [01:12<01:19,  1.50s/it]\u001b[A\n",
            "training set:  49%|████▊     | 49/101 [01:13<01:18,  1.51s/it]\u001b[A\n",
            "training set:  50%|████▉     | 50/101 [01:15<01:16,  1.51s/it]\u001b[A\n",
            "training set:  50%|█████     | 51/101 [01:16<01:15,  1.51s/it]\u001b[A\n",
            "training set:  51%|█████▏    | 52/101 [01:18<01:14,  1.53s/it]\u001b[A\n",
            "training set:  52%|█████▏    | 53/101 [01:20<01:13,  1.53s/it]\u001b[A\n",
            "training set:  53%|█████▎    | 54/101 [01:21<01:11,  1.53s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 55/101 [01:23<01:09,  1.52s/it]\u001b[A\n",
            "training set:  55%|█████▌    | 56/101 [01:24<01:08,  1.51s/it]\u001b[A\n",
            "training set:  56%|█████▋    | 57/101 [01:26<01:06,  1.51s/it]\u001b[A\n",
            "training set:  57%|█████▋    | 58/101 [01:27<01:04,  1.51s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 59/101 [01:29<01:02,  1.49s/it]\u001b[A\n",
            "training set:  59%|█████▉    | 60/101 [01:30<01:01,  1.49s/it]\u001b[A\n",
            "training set:  60%|██████    | 61/101 [01:32<00:59,  1.50s/it]\u001b[A\n",
            "training set:  61%|██████▏   | 62/101 [01:33<00:58,  1.50s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 63/101 [01:35<00:57,  1.51s/it]\u001b[A\n",
            "training set:  63%|██████▎   | 64/101 [01:36<00:56,  1.51s/it]\u001b[A\n",
            "training set:  64%|██████▍   | 65/101 [01:38<00:54,  1.52s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 66/101 [01:39<00:53,  1.52s/it]\u001b[A\n",
            "training set:  66%|██████▋   | 67/101 [01:41<00:51,  1.51s/it]\u001b[A\n",
            "training set:  67%|██████▋   | 68/101 [01:42<00:49,  1.51s/it]\u001b[A\n",
            "training set:  68%|██████▊   | 69/101 [01:44<00:48,  1.51s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 70/101 [01:45<00:46,  1.50s/it]\u001b[A\n",
            "training set:  70%|███████   | 71/101 [01:47<00:44,  1.49s/it]\u001b[A\n",
            "training set:  71%|███████▏  | 72/101 [01:48<00:43,  1.49s/it]\u001b[A\n",
            "training set:  72%|███████▏  | 73/101 [01:50<00:41,  1.49s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 74/101 [01:51<00:40,  1.50s/it]\u001b[A\n",
            "training set:  74%|███████▍  | 75/101 [01:53<00:38,  1.50s/it]\u001b[A\n",
            "training set:  75%|███████▌  | 76/101 [01:54<00:37,  1.50s/it]\u001b[A\n",
            "training set:  76%|███████▌  | 77/101 [01:56<00:36,  1.51s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 78/101 [01:57<00:34,  1.52s/it]\u001b[A\n",
            "training set:  78%|███████▊  | 79/101 [01:59<00:33,  1.52s/it]\u001b[A\n",
            "training set:  79%|███████▉  | 80/101 [02:00<00:31,  1.52s/it]\u001b[A\n",
            "training set:  80%|████████  | 81/101 [02:02<00:30,  1.51s/it]\u001b[A\n",
            "training set:  81%|████████  | 82/101 [02:03<00:28,  1.51s/it]\u001b[A\n",
            "training set:  82%|████████▏ | 83/101 [02:05<00:27,  1.50s/it]\u001b[A\n",
            "training set:  83%|████████▎ | 84/101 [02:06<00:25,  1.50s/it]\u001b[A\n",
            "training set:  84%|████████▍ | 85/101 [02:08<00:23,  1.49s/it]\u001b[A\n",
            "training set:  85%|████████▌ | 86/101 [02:09<00:22,  1.50s/it]\u001b[A\n",
            "training set:  86%|████████▌ | 87/101 [02:11<00:20,  1.50s/it]\u001b[A\n",
            "training set:  87%|████████▋ | 88/101 [02:12<00:19,  1.51s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 89/101 [02:14<00:18,  1.52s/it]\u001b[A\n",
            "training set:  89%|████████▉ | 90/101 [02:15<00:16,  1.51s/it]\u001b[A\n",
            "training set:  90%|█████████ | 91/101 [02:17<00:15,  1.52s/it]\u001b[A\n",
            "training set:  91%|█████████ | 92/101 [02:18<00:13,  1.52s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 93/101 [02:20<00:12,  1.52s/it]\u001b[A\n",
            "training set:  93%|█████████▎| 94/101 [02:21<00:10,  1.51s/it]\u001b[A\n",
            "training set:  94%|█████████▍| 95/101 [02:23<00:09,  1.51s/it]\u001b[A\n",
            "training set:  95%|█████████▌| 96/101 [02:24<00:07,  1.50s/it]\u001b[A\n",
            "training set:  96%|█████████▌| 97/101 [02:26<00:05,  1.50s/it]\u001b[A\n",
            "training set:  97%|█████████▋| 98/101 [02:27<00:04,  1.50s/it]\u001b[A\n",
            "training set:  98%|█████████▊| 99/101 [02:29<00:02,  1.50s/it]\u001b[A\n",
            "training set:  99%|█████████▉| 100/101 [02:30<00:01,  1.50s/it]\u001b[A\n",
            "training set: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n",
            "\n",
            "dev set:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   8%|▊         | 1/12 [00:00<00:05,  1.96it/s]\u001b[A\n",
            "dev set:  17%|█▋        | 2/12 [00:01<00:05,  1.89it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 3/12 [00:01<00:04,  1.87it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 4/12 [00:02<00:04,  1.88it/s]\u001b[A\n",
            "dev set:  42%|████▏     | 5/12 [00:02<00:03,  1.88it/s]\u001b[A\n",
            "dev set:  50%|█████     | 6/12 [00:03<00:03,  1.86it/s]\u001b[A\n",
            "dev set:  58%|█████▊    | 7/12 [00:03<00:02,  1.84it/s]\u001b[A\n",
            "dev set:  67%|██████▋   | 8/12 [00:04<00:02,  1.84it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 9/12 [00:04<00:01,  1.84it/s]\u001b[A\n",
            "dev set:  83%|████████▎ | 10/12 [00:05<00:01,  1.85it/s]\u001b[A\n",
            "dev set: 100%|██████████| 12/12 [00:05<00:00,  2.01it/s]\n",
            "\n",
            "dev set:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   4%|▎         | 1/28 [00:00<00:13,  1.95it/s]\u001b[A\n",
            "dev set:   7%|▋         | 2/28 [00:01<00:13,  1.91it/s]\u001b[A\n",
            "dev set:  11%|█         | 3/28 [00:01<00:13,  1.91it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 4/28 [00:02<00:12,  1.91it/s]\u001b[A\n",
            "dev set:  18%|█▊        | 5/28 [00:02<00:11,  1.92it/s]\u001b[A\n",
            "dev set:  21%|██▏       | 6/28 [00:03<00:11,  1.94it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 7/28 [00:03<00:10,  1.93it/s]\u001b[A\n",
            "dev set:  29%|██▊       | 8/28 [00:04<00:10,  1.93it/s]\u001b[A\n",
            "dev set:  32%|███▏      | 9/28 [00:04<00:09,  1.94it/s]\u001b[A\n",
            "dev set:  36%|███▌      | 10/28 [00:05<00:09,  1.94it/s]\u001b[A\n",
            "dev set:  39%|███▉      | 11/28 [00:05<00:08,  1.93it/s]\u001b[A\n",
            "dev set:  43%|████▎     | 12/28 [00:06<00:08,  1.94it/s]\u001b[A\n",
            "dev set:  46%|████▋     | 13/28 [00:06<00:07,  1.94it/s]\u001b[A\n",
            "dev set:  50%|█████     | 14/28 [00:07<00:07,  1.93it/s]\u001b[A\n",
            "dev set:  54%|█████▎    | 15/28 [00:07<00:06,  1.93it/s]\u001b[A\n",
            "dev set:  57%|█████▋    | 16/28 [00:08<00:06,  1.93it/s]\u001b[A\n",
            "dev set:  61%|██████    | 17/28 [00:08<00:05,  1.94it/s]\u001b[A\n",
            "dev set:  64%|██████▍   | 18/28 [00:09<00:05,  1.93it/s]\u001b[A\n",
            "dev set:  68%|██████▊   | 19/28 [00:09<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  71%|███████▏  | 20/28 [00:10<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 21/28 [00:10<00:03,  1.95it/s]\u001b[A\n",
            "dev set:  79%|███████▊  | 22/28 [00:11<00:03,  1.93it/s]\u001b[A\n",
            "dev set:  82%|████████▏ | 23/28 [00:11<00:02,  1.95it/s]\u001b[A\n",
            "dev set:  86%|████████▌ | 24/28 [00:12<00:02,  1.93it/s]\u001b[A\n",
            "dev set:  89%|████████▉ | 25/28 [00:12<00:01,  1.90it/s]\u001b[A\n",
            "dev set:  93%|█████████▎| 26/28 [00:13<00:01,  1.89it/s]\u001b[A\n",
            "dev set:  96%|█████████▋| 27/28 [00:14<00:00,  1.88it/s]\u001b[A\n",
            "dev set: 100%|██████████| 28/28 [00:14<00:00,  1.93it/s]\n",
            " 40%|████      | 2/5 [05:43<08:35, 171.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 1.6945 Validation loss: 1.6350 Test loss: 1.6764\n",
            "Train accuracy: 0.2066 Validation accuracy: 0.2247 Test accuracy: 0.2090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   1%|          | 1/101 [00:01<02:32,  1.52s/it]\u001b[A\n",
            "training set:   2%|▏         | 2/101 [00:03<02:30,  1.52s/it]\u001b[A\n",
            "training set:   3%|▎         | 3/101 [00:04<02:28,  1.52s/it]\u001b[A\n",
            "training set:   4%|▍         | 4/101 [00:06<02:26,  1.52s/it]\u001b[A\n",
            "training set:   5%|▍         | 5/101 [00:07<02:25,  1.51s/it]\u001b[A\n",
            "training set:   6%|▌         | 6/101 [00:09<02:23,  1.51s/it]\u001b[A\n",
            "training set:   7%|▋         | 7/101 [00:10<02:21,  1.50s/it]\u001b[A\n",
            "training set:   8%|▊         | 8/101 [00:12<02:18,  1.49s/it]\u001b[A\n",
            "training set:   9%|▉         | 9/101 [00:13<02:17,  1.50s/it]\u001b[A\n",
            "training set:  10%|▉         | 10/101 [00:15<02:16,  1.50s/it]\u001b[A\n",
            "training set:  11%|█         | 11/101 [00:16<02:14,  1.49s/it]\u001b[A\n",
            "training set:  12%|█▏        | 12/101 [00:18<02:13,  1.50s/it]\u001b[A\n",
            "training set:  13%|█▎        | 13/101 [00:19<02:12,  1.51s/it]\u001b[A\n",
            "training set:  14%|█▍        | 14/101 [00:21<02:11,  1.51s/it]\u001b[A\n",
            "training set:  15%|█▍        | 15/101 [00:22<02:10,  1.51s/it]\u001b[A\n",
            "training set:  16%|█▌        | 16/101 [00:24<02:09,  1.52s/it]\u001b[A\n",
            "training set:  17%|█▋        | 17/101 [00:25<02:08,  1.52s/it]\u001b[A\n",
            "training set:  18%|█▊        | 18/101 [00:27<02:05,  1.52s/it]\u001b[A\n",
            "training set:  19%|█▉        | 19/101 [00:28<02:04,  1.52s/it]\u001b[A\n",
            "training set:  20%|█▉        | 20/101 [00:30<02:02,  1.51s/it]\u001b[A\n",
            "training set:  21%|██        | 21/101 [00:31<02:00,  1.51s/it]\u001b[A\n",
            "training set:  22%|██▏       | 22/101 [00:33<01:59,  1.51s/it]\u001b[A\n",
            "training set:  23%|██▎       | 23/101 [00:34<01:57,  1.51s/it]\u001b[A\n",
            "training set:  24%|██▍       | 24/101 [00:36<01:56,  1.51s/it]\u001b[A\n",
            "training set:  25%|██▍       | 25/101 [00:37<01:54,  1.51s/it]\u001b[A\n",
            "training set:  26%|██▌       | 26/101 [00:39<01:53,  1.52s/it]\u001b[A\n",
            "training set:  27%|██▋       | 27/101 [00:40<01:52,  1.52s/it]\u001b[A\n",
            "training set:  28%|██▊       | 28/101 [00:42<01:50,  1.52s/it]\u001b[A\n",
            "training set:  29%|██▊       | 29/101 [00:43<01:49,  1.52s/it]\u001b[A\n",
            "training set:  30%|██▉       | 30/101 [00:45<01:48,  1.53s/it]\u001b[A\n",
            "training set:  31%|███       | 31/101 [00:46<01:46,  1.53s/it]\u001b[A\n",
            "training set:  32%|███▏      | 32/101 [00:48<01:44,  1.52s/it]\u001b[A\n",
            "training set:  33%|███▎      | 33/101 [00:49<01:42,  1.51s/it]\u001b[A\n",
            "training set:  34%|███▎      | 34/101 [00:51<01:41,  1.51s/it]\u001b[A\n",
            "training set:  35%|███▍      | 35/101 [00:52<01:39,  1.50s/it]\u001b[A\n",
            "training set:  36%|███▌      | 36/101 [00:54<01:37,  1.50s/it]\u001b[A\n",
            "training set:  37%|███▋      | 37/101 [00:55<01:36,  1.50s/it]\u001b[A\n",
            "training set:  38%|███▊      | 38/101 [00:57<01:34,  1.50s/it]\u001b[A\n",
            "training set:  39%|███▊      | 39/101 [00:58<01:33,  1.51s/it]\u001b[A\n",
            "training set:  40%|███▉      | 40/101 [01:00<01:32,  1.51s/it]\u001b[A\n",
            "training set:  41%|████      | 41/101 [01:01<01:30,  1.51s/it]\u001b[A\n",
            "training set:  42%|████▏     | 42/101 [01:03<01:29,  1.52s/it]\u001b[A\n",
            "training set:  43%|████▎     | 43/101 [01:04<01:28,  1.52s/it]\u001b[A\n",
            "training set:  44%|████▎     | 44/101 [01:06<01:26,  1.52s/it]\u001b[A\n",
            "training set:  45%|████▍     | 45/101 [01:07<01:24,  1.51s/it]\u001b[A\n",
            "training set:  46%|████▌     | 46/101 [01:09<01:22,  1.50s/it]\u001b[A\n",
            "training set:  47%|████▋     | 47/101 [01:10<01:20,  1.50s/it]\u001b[A\n",
            "training set:  48%|████▊     | 48/101 [01:12<01:19,  1.50s/it]\u001b[A\n",
            "training set:  49%|████▊     | 49/101 [01:13<01:18,  1.50s/it]\u001b[A\n",
            "training set:  50%|████▉     | 50/101 [01:15<01:16,  1.50s/it]\u001b[A\n",
            "training set:  50%|█████     | 51/101 [01:16<01:15,  1.50s/it]\u001b[A\n",
            "training set:  51%|█████▏    | 52/101 [01:18<01:13,  1.51s/it]\u001b[A\n",
            "training set:  52%|█████▏    | 53/101 [01:19<01:12,  1.50s/it]\u001b[A\n",
            "training set:  53%|█████▎    | 54/101 [01:21<01:11,  1.51s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 55/101 [01:23<01:09,  1.51s/it]\u001b[A\n",
            "training set:  55%|█████▌    | 56/101 [01:24<01:08,  1.51s/it]\u001b[A\n",
            "training set:  56%|█████▋    | 57/101 [01:26<01:06,  1.51s/it]\u001b[A\n",
            "training set:  57%|█████▋    | 58/101 [01:27<01:04,  1.50s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 59/101 [01:29<01:02,  1.50s/it]\u001b[A\n",
            "training set:  59%|█████▉    | 60/101 [01:30<01:01,  1.50s/it]\u001b[A\n",
            "training set:  60%|██████    | 61/101 [01:32<00:59,  1.50s/it]\u001b[A\n",
            "training set:  61%|██████▏   | 62/101 [01:33<00:58,  1.50s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 63/101 [01:35<00:57,  1.50s/it]\u001b[A\n",
            "training set:  63%|██████▎   | 64/101 [01:36<00:55,  1.50s/it]\u001b[A\n",
            "training set:  64%|██████▍   | 65/101 [01:38<00:54,  1.51s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 66/101 [01:39<00:52,  1.51s/it]\u001b[A\n",
            "training set:  66%|██████▋   | 67/101 [01:41<00:51,  1.50s/it]\u001b[A\n",
            "training set:  67%|██████▋   | 68/101 [01:42<00:49,  1.51s/it]\u001b[A\n",
            "training set:  68%|██████▊   | 69/101 [01:44<00:48,  1.51s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 70/101 [01:45<00:46,  1.51s/it]\u001b[A\n",
            "training set:  70%|███████   | 71/101 [01:47<00:45,  1.50s/it]\u001b[A\n",
            "training set:  71%|███████▏  | 72/101 [01:48<00:43,  1.50s/it]\u001b[A\n",
            "training set:  72%|███████▏  | 73/101 [01:50<00:41,  1.50s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 74/101 [01:51<00:40,  1.50s/it]\u001b[A\n",
            "training set:  74%|███████▍  | 75/101 [01:53<00:38,  1.50s/it]\u001b[A\n",
            "training set:  75%|███████▌  | 76/101 [01:54<00:37,  1.50s/it]\u001b[A\n",
            "training set:  76%|███████▌  | 77/101 [01:56<00:36,  1.51s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 78/101 [01:57<00:34,  1.51s/it]\u001b[A\n",
            "training set:  78%|███████▊  | 79/101 [01:59<00:33,  1.52s/it]\u001b[A\n",
            "training set:  79%|███████▉  | 80/101 [02:00<00:32,  1.52s/it]\u001b[A\n",
            "training set:  80%|████████  | 81/101 [02:02<00:30,  1.53s/it]\u001b[A\n",
            "training set:  81%|████████  | 82/101 [02:03<00:29,  1.53s/it]\u001b[A\n",
            "training set:  82%|████████▏ | 83/101 [02:05<00:27,  1.52s/it]\u001b[A\n",
            "training set:  83%|████████▎ | 84/101 [02:06<00:25,  1.52s/it]\u001b[A\n",
            "training set:  84%|████████▍ | 85/101 [02:08<00:24,  1.51s/it]\u001b[A\n",
            "training set:  85%|████████▌ | 86/101 [02:09<00:22,  1.50s/it]\u001b[A\n",
            "training set:  86%|████████▌ | 87/101 [02:11<00:21,  1.50s/it]\u001b[A\n",
            "training set:  87%|████████▋ | 88/101 [02:12<00:19,  1.50s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 89/101 [02:14<00:17,  1.50s/it]\u001b[A\n",
            "training set:  89%|████████▉ | 90/101 [02:15<00:16,  1.50s/it]\u001b[A\n",
            "training set:  90%|█████████ | 91/101 [02:17<00:15,  1.50s/it]\u001b[A\n",
            "training set:  91%|█████████ | 92/101 [02:18<00:13,  1.51s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 93/101 [02:20<00:12,  1.52s/it]\u001b[A\n",
            "training set:  93%|█████████▎| 94/101 [02:21<00:10,  1.51s/it]\u001b[A\n",
            "training set:  94%|█████████▍| 95/101 [02:23<00:09,  1.52s/it]\u001b[A\n",
            "training set:  95%|█████████▌| 96/101 [02:24<00:07,  1.52s/it]\u001b[A\n",
            "training set:  96%|█████████▌| 97/101 [02:26<00:06,  1.51s/it]\u001b[A\n",
            "training set:  97%|█████████▋| 98/101 [02:27<00:04,  1.51s/it]\u001b[A\n",
            "training set:  98%|█████████▊| 99/101 [02:29<00:03,  1.50s/it]\u001b[A\n",
            "training set:  99%|█████████▉| 100/101 [02:30<00:01,  1.50s/it]\u001b[A\n",
            "training set: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n",
            "\n",
            "dev set:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   8%|▊         | 1/12 [00:00<00:05,  2.01it/s]\u001b[A\n",
            "dev set:  17%|█▋        | 2/12 [00:01<00:05,  1.94it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 3/12 [00:01<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 4/12 [00:02<00:04,  1.93it/s]\u001b[A\n",
            "dev set:  42%|████▏     | 5/12 [00:02<00:03,  1.94it/s]\u001b[A\n",
            "dev set:  50%|█████     | 6/12 [00:03<00:03,  1.94it/s]\u001b[A\n",
            "dev set:  58%|█████▊    | 7/12 [00:03<00:02,  1.93it/s]\u001b[A\n",
            "dev set:  67%|██████▋   | 8/12 [00:04<00:02,  1.91it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 9/12 [00:04<00:01,  1.89it/s]\u001b[A\n",
            "dev set:  83%|████████▎ | 10/12 [00:05<00:01,  1.86it/s]\u001b[A\n",
            "dev set: 100%|██████████| 12/12 [00:05<00:00,  2.05it/s]\n",
            "\n",
            "dev set:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   4%|▎         | 1/28 [00:00<00:14,  1.87it/s]\u001b[A\n",
            "dev set:   7%|▋         | 2/28 [00:01<00:13,  1.89it/s]\u001b[A\n",
            "dev set:  11%|█         | 3/28 [00:01<00:13,  1.89it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 4/28 [00:02<00:12,  1.89it/s]\u001b[A\n",
            "dev set:  18%|█▊        | 5/28 [00:02<00:12,  1.88it/s]\u001b[A\n",
            "dev set:  21%|██▏       | 6/28 [00:03<00:11,  1.89it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 7/28 [00:03<00:11,  1.87it/s]\u001b[A\n",
            "dev set:  29%|██▊       | 8/28 [00:04<00:10,  1.86it/s]\u001b[A\n",
            "dev set:  32%|███▏      | 9/28 [00:04<00:10,  1.87it/s]\u001b[A\n",
            "dev set:  36%|███▌      | 10/28 [00:05<00:09,  1.87it/s]\u001b[A\n",
            "dev set:  39%|███▉      | 11/28 [00:05<00:09,  1.87it/s]\u001b[A\n",
            "dev set:  43%|████▎     | 12/28 [00:06<00:08,  1.86it/s]\u001b[A\n",
            "dev set:  46%|████▋     | 13/28 [00:06<00:08,  1.87it/s]\u001b[A\n",
            "dev set:  50%|█████     | 14/28 [00:07<00:07,  1.88it/s]\u001b[A\n",
            "dev set:  54%|█████▎    | 15/28 [00:07<00:06,  1.88it/s]\u001b[A\n",
            "dev set:  57%|█████▋    | 16/28 [00:08<00:06,  1.90it/s]\u001b[A\n",
            "dev set:  61%|██████    | 17/28 [00:09<00:05,  1.92it/s]\u001b[A\n",
            "dev set:  64%|██████▍   | 18/28 [00:09<00:05,  1.93it/s]\u001b[A\n",
            "dev set:  68%|██████▊   | 19/28 [00:10<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  71%|███████▏  | 20/28 [00:10<00:04,  1.93it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 21/28 [00:11<00:03,  1.93it/s]\u001b[A\n",
            "dev set:  79%|███████▊  | 22/28 [00:11<00:03,  1.93it/s]\u001b[A\n",
            "dev set:  82%|████████▏ | 23/28 [00:12<00:02,  1.94it/s]\u001b[A\n",
            "dev set:  86%|████████▌ | 24/28 [00:12<00:02,  1.95it/s]\u001b[A\n",
            "dev set:  89%|████████▉ | 25/28 [00:13<00:01,  1.94it/s]\u001b[A\n",
            "dev set:  93%|█████████▎| 26/28 [00:13<00:01,  1.93it/s]\u001b[A\n",
            "dev set:  96%|█████████▋| 27/28 [00:14<00:00,  1.92it/s]\u001b[A\n",
            "dev set: 100%|██████████| 28/28 [00:14<00:00,  1.92it/s]\n",
            " 60%|██████    | 3/5 [08:35<05:43, 171.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 1.6775 Validation loss: 1.6537 Test loss: 1.6211\n",
            "Train accuracy: 0.2116 Validation accuracy: 0.1685 Test accuracy: 0.2022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   1%|          | 1/101 [00:01<02:28,  1.49s/it]\u001b[A\n",
            "training set:   2%|▏         | 2/101 [00:02<02:27,  1.49s/it]\u001b[A\n",
            "training set:   3%|▎         | 3/101 [00:04<02:27,  1.51s/it]\u001b[A\n",
            "training set:   4%|▍         | 4/101 [00:06<02:26,  1.51s/it]\u001b[A\n",
            "training set:   5%|▍         | 5/101 [00:07<02:26,  1.53s/it]\u001b[A\n",
            "training set:   6%|▌         | 6/101 [00:09<02:25,  1.53s/it]\u001b[A\n",
            "training set:   7%|▋         | 7/101 [00:10<02:23,  1.53s/it]\u001b[A\n",
            "training set:   8%|▊         | 8/101 [00:12<02:21,  1.52s/it]\u001b[A\n",
            "training set:   9%|▉         | 9/101 [00:13<02:19,  1.52s/it]\u001b[A\n",
            "training set:  10%|▉         | 10/101 [00:15<02:17,  1.51s/it]\u001b[A\n",
            "training set:  11%|█         | 11/101 [00:16<02:16,  1.51s/it]\u001b[A\n",
            "training set:  12%|█▏        | 12/101 [00:18<02:14,  1.51s/it]\u001b[A\n",
            "training set:  13%|█▎        | 13/101 [00:19<02:12,  1.51s/it]\u001b[A\n",
            "training set:  14%|█▍        | 14/101 [00:21<02:11,  1.51s/it]\u001b[A\n",
            "training set:  15%|█▍        | 15/101 [00:22<02:09,  1.51s/it]\u001b[A\n",
            "training set:  16%|█▌        | 16/101 [00:24<02:07,  1.50s/it]\u001b[A\n",
            "training set:  17%|█▋        | 17/101 [00:25<02:06,  1.51s/it]\u001b[A\n",
            "training set:  18%|█▊        | 18/101 [00:27<02:05,  1.51s/it]\u001b[A\n",
            "training set:  19%|█▉        | 19/101 [00:28<02:04,  1.51s/it]\u001b[A\n",
            "training set:  20%|█▉        | 20/101 [00:30<02:02,  1.52s/it]\u001b[A\n",
            "training set:  21%|██        | 21/101 [00:31<02:02,  1.53s/it]\u001b[A\n",
            "training set:  22%|██▏       | 22/101 [00:33<01:59,  1.52s/it]\u001b[A\n",
            "training set:  23%|██▎       | 23/101 [00:34<01:57,  1.51s/it]\u001b[A\n",
            "training set:  24%|██▍       | 24/101 [00:36<01:55,  1.50s/it]\u001b[A\n",
            "training set:  25%|██▍       | 25/101 [00:37<01:54,  1.50s/it]\u001b[A\n",
            "training set:  26%|██▌       | 26/101 [00:39<01:52,  1.50s/it]\u001b[A\n",
            "training set:  27%|██▋       | 27/101 [00:40<01:50,  1.50s/it]\u001b[A\n",
            "training set:  28%|██▊       | 28/101 [00:42<01:49,  1.50s/it]\u001b[A\n",
            "training set:  29%|██▊       | 29/101 [00:43<01:48,  1.50s/it]\u001b[A\n",
            "training set:  30%|██▉       | 30/101 [00:45<01:47,  1.51s/it]\u001b[A\n",
            "training set:  31%|███       | 31/101 [00:46<01:45,  1.51s/it]\u001b[A\n",
            "training set:  32%|███▏      | 32/101 [00:48<01:44,  1.52s/it]\u001b[A\n",
            "training set:  33%|███▎      | 33/101 [00:49<01:43,  1.52s/it]\u001b[A\n",
            "training set:  34%|███▎      | 34/101 [00:51<01:42,  1.52s/it]\u001b[A\n",
            "training set:  35%|███▍      | 35/101 [00:52<01:40,  1.52s/it]\u001b[A\n",
            "training set:  36%|███▌      | 36/101 [00:54<01:38,  1.51s/it]\u001b[A\n",
            "training set:  37%|███▋      | 37/101 [00:55<01:36,  1.50s/it]\u001b[A\n",
            "training set:  38%|███▊      | 38/101 [00:57<01:34,  1.50s/it]\u001b[A\n",
            "training set:  39%|███▊      | 39/101 [00:58<01:32,  1.50s/it]\u001b[A\n",
            "training set:  40%|███▉      | 40/101 [01:00<01:31,  1.50s/it]\u001b[A\n",
            "training set:  41%|████      | 41/101 [01:01<01:29,  1.50s/it]\u001b[A\n",
            "training set:  42%|████▏     | 42/101 [01:03<01:28,  1.50s/it]\u001b[A\n",
            "training set:  43%|████▎     | 43/101 [01:04<01:27,  1.51s/it]\u001b[A\n",
            "training set:  44%|████▎     | 44/101 [01:06<01:26,  1.52s/it]\u001b[A\n",
            "training set:  45%|████▍     | 45/101 [01:08<01:25,  1.53s/it]\u001b[A\n",
            "training set:  46%|████▌     | 46/101 [01:09<01:23,  1.53s/it]\u001b[A\n",
            "training set:  47%|████▋     | 47/101 [01:11<01:22,  1.52s/it]\u001b[A\n",
            "training set:  48%|████▊     | 48/101 [01:12<01:20,  1.51s/it]\u001b[A\n",
            "training set:  49%|████▊     | 49/101 [01:14<01:18,  1.51s/it]\u001b[A\n",
            "training set:  50%|████▉     | 50/101 [01:15<01:16,  1.50s/it]\u001b[A\n",
            "training set:  50%|█████     | 51/101 [01:17<01:15,  1.51s/it]\u001b[A\n",
            "training set:  51%|█████▏    | 52/101 [01:18<01:13,  1.50s/it]\u001b[A\n",
            "training set:  52%|█████▏    | 53/101 [01:20<01:12,  1.51s/it]\u001b[A\n",
            "training set:  53%|█████▎    | 54/101 [01:21<01:11,  1.52s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 55/101 [01:23<01:10,  1.53s/it]\u001b[A\n",
            "training set:  55%|█████▌    | 56/101 [01:24<01:09,  1.54s/it]\u001b[A\n",
            "training set:  56%|█████▋    | 57/101 [01:26<01:07,  1.54s/it]\u001b[A\n",
            "training set:  57%|█████▋    | 58/101 [01:27<01:05,  1.53s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 59/101 [01:29<01:03,  1.52s/it]\u001b[A\n",
            "training set:  59%|█████▉    | 60/101 [01:30<01:02,  1.52s/it]\u001b[A\n",
            "training set:  60%|██████    | 61/101 [01:32<01:00,  1.51s/it]\u001b[A\n",
            "training set:  61%|██████▏   | 62/101 [01:33<00:58,  1.51s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 63/101 [01:35<00:57,  1.50s/it]\u001b[A\n",
            "training set:  63%|██████▎   | 64/101 [01:36<00:55,  1.50s/it]\u001b[A\n",
            "training set:  64%|██████▍   | 65/101 [01:38<00:53,  1.50s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 66/101 [01:39<00:52,  1.50s/it]\u001b[A\n",
            "training set:  66%|██████▋   | 67/101 [01:41<00:51,  1.50s/it]\u001b[A\n",
            "training set:  67%|██████▋   | 68/101 [01:42<00:49,  1.51s/it]\u001b[A\n",
            "training set:  68%|██████▊   | 69/101 [01:44<00:48,  1.52s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 70/101 [01:45<00:47,  1.53s/it]\u001b[A\n",
            "training set:  70%|███████   | 71/101 [01:47<00:45,  1.53s/it]\u001b[A\n",
            "training set:  71%|███████▏  | 72/101 [01:48<00:44,  1.53s/it]\u001b[A\n",
            "training set:  72%|███████▏  | 73/101 [01:50<00:42,  1.52s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 74/101 [01:51<00:40,  1.51s/it]\u001b[A\n",
            "training set:  74%|███████▍  | 75/101 [01:53<00:39,  1.50s/it]\u001b[A\n",
            "training set:  75%|███████▌  | 76/101 [01:54<00:37,  1.50s/it]\u001b[A\n",
            "training set:  76%|███████▌  | 77/101 [01:56<00:35,  1.50s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 78/101 [01:57<00:34,  1.49s/it]\u001b[A\n",
            "training set:  78%|███████▊  | 79/101 [01:59<00:32,  1.50s/it]\u001b[A\n",
            "training set:  79%|███████▉  | 80/101 [02:00<00:31,  1.51s/it]\u001b[A\n",
            "training set:  80%|████████  | 81/101 [02:02<00:30,  1.51s/it]\u001b[A\n",
            "training set:  81%|████████  | 82/101 [02:03<00:28,  1.52s/it]\u001b[A\n",
            "training set:  82%|████████▏ | 83/101 [02:05<00:27,  1.52s/it]\u001b[A\n",
            "training set:  83%|████████▎ | 84/101 [02:07<00:25,  1.52s/it]\u001b[A\n",
            "training set:  84%|████████▍ | 85/101 [02:08<00:24,  1.52s/it]\u001b[A\n",
            "training set:  85%|████████▌ | 86/101 [02:10<00:22,  1.52s/it]\u001b[A\n",
            "training set:  86%|████████▌ | 87/101 [02:11<00:21,  1.51s/it]\u001b[A\n",
            "training set:  87%|████████▋ | 88/101 [02:13<00:19,  1.51s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 89/101 [02:14<00:18,  1.51s/it]\u001b[A\n",
            "training set:  89%|████████▉ | 90/101 [02:16<00:16,  1.51s/it]\u001b[A\n",
            "training set:  90%|█████████ | 91/101 [02:17<00:15,  1.50s/it]\u001b[A\n",
            "training set:  91%|█████████ | 92/101 [02:19<00:13,  1.50s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 93/101 [02:20<00:12,  1.51s/it]\u001b[A\n",
            "training set:  93%|█████████▎| 94/101 [02:22<00:10,  1.51s/it]\u001b[A\n",
            "training set:  94%|█████████▍| 95/101 [02:23<00:09,  1.51s/it]\u001b[A\n",
            "training set:  95%|█████████▌| 96/101 [02:25<00:07,  1.51s/it]\u001b[A\n",
            "training set:  96%|█████████▌| 97/101 [02:26<00:06,  1.52s/it]\u001b[A\n",
            "training set:  97%|█████████▋| 98/101 [02:28<00:04,  1.52s/it]\u001b[A\n",
            "training set:  98%|█████████▊| 99/101 [02:29<00:03,  1.51s/it]\u001b[A\n",
            "training set:  99%|█████████▉| 100/101 [02:31<00:01,  1.51s/it]\u001b[A\n",
            "training set: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n",
            "\n",
            "dev set:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   8%|▊         | 1/12 [00:00<00:05,  2.02it/s]\u001b[A\n",
            "dev set:  17%|█▋        | 2/12 [00:01<00:05,  1.97it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 3/12 [00:01<00:04,  1.96it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 4/12 [00:02<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  42%|████▏     | 5/12 [00:02<00:03,  1.94it/s]\u001b[A\n",
            "dev set:  50%|█████     | 6/12 [00:03<00:03,  1.94it/s]\u001b[A\n",
            "dev set:  58%|█████▊    | 7/12 [00:03<00:02,  1.93it/s]\u001b[A\n",
            "dev set:  67%|██████▋   | 8/12 [00:04<00:02,  1.92it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 9/12 [00:04<00:01,  1.91it/s]\u001b[A\n",
            "dev set:  83%|████████▎ | 10/12 [00:05<00:01,  1.92it/s]\u001b[A\n",
            "dev set: 100%|██████████| 12/12 [00:05<00:00,  2.08it/s]\n",
            "\n",
            "dev set:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   4%|▎         | 1/28 [00:00<00:13,  1.95it/s]\u001b[A\n",
            "dev set:   7%|▋         | 2/28 [00:01<00:13,  1.94it/s]\u001b[A\n",
            "dev set:  11%|█         | 3/28 [00:01<00:12,  1.93it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 4/28 [00:02<00:12,  1.90it/s]\u001b[A\n",
            "dev set:  18%|█▊        | 5/28 [00:02<00:12,  1.91it/s]\u001b[A\n",
            "dev set:  21%|██▏       | 6/28 [00:03<00:11,  1.90it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 7/28 [00:03<00:11,  1.87it/s]\u001b[A\n",
            "dev set:  29%|██▊       | 8/28 [00:04<00:10,  1.88it/s]\u001b[A\n",
            "dev set:  32%|███▏      | 9/28 [00:04<00:10,  1.89it/s]\u001b[A\n",
            "dev set:  36%|███▌      | 10/28 [00:05<00:09,  1.89it/s]\u001b[A\n",
            "dev set:  39%|███▉      | 11/28 [00:05<00:09,  1.88it/s]\u001b[A\n",
            "dev set:  43%|████▎     | 12/28 [00:06<00:08,  1.88it/s]\u001b[A\n",
            "dev set:  46%|████▋     | 13/28 [00:06<00:08,  1.87it/s]\u001b[A\n",
            "dev set:  50%|█████     | 14/28 [00:07<00:07,  1.85it/s]\u001b[A\n",
            "dev set:  54%|█████▎    | 15/28 [00:07<00:07,  1.84it/s]\u001b[A\n",
            "dev set:  57%|█████▋    | 16/28 [00:08<00:06,  1.84it/s]\u001b[A\n",
            "dev set:  61%|██████    | 17/28 [00:09<00:05,  1.85it/s]\u001b[A\n",
            "dev set:  64%|██████▍   | 18/28 [00:09<00:05,  1.84it/s]\u001b[A\n",
            "dev set:  68%|██████▊   | 19/28 [00:10<00:04,  1.85it/s]\u001b[A\n",
            "dev set:  71%|███████▏  | 20/28 [00:10<00:04,  1.85it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 21/28 [00:11<00:03,  1.88it/s]\u001b[A\n",
            "dev set:  79%|███████▊  | 22/28 [00:11<00:03,  1.90it/s]\u001b[A\n",
            "dev set:  82%|████████▏ | 23/28 [00:12<00:02,  1.91it/s]\u001b[A\n",
            "dev set:  86%|████████▌ | 24/28 [00:12<00:02,  1.92it/s]\u001b[A\n",
            "dev set:  89%|████████▉ | 25/28 [00:13<00:01,  1.93it/s]\u001b[A\n",
            "dev set:  93%|█████████▎| 26/28 [00:13<00:01,  1.94it/s]\u001b[A\n",
            "dev set:  96%|█████████▋| 27/28 [00:14<00:00,  1.93it/s]\u001b[A\n",
            "dev set: 100%|██████████| 28/28 [00:14<00:00,  1.90it/s]\n",
            " 80%|████████  | 4/5 [11:27<02:51, 171.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 1.6958 Validation loss: 1.9191 Test loss: 2.0014\n",
            "Train accuracy: 0.2041 Validation accuracy: 0.2416 Test accuracy: 0.2404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   1%|          | 1/101 [00:01<02:28,  1.49s/it]\u001b[A\n",
            "training set:   2%|▏         | 2/101 [00:03<02:29,  1.51s/it]\u001b[A\n",
            "training set:   3%|▎         | 3/101 [00:04<02:27,  1.51s/it]\u001b[A\n",
            "training set:   4%|▍         | 4/101 [00:06<02:25,  1.50s/it]\u001b[A\n",
            "training set:   5%|▍         | 5/101 [00:07<02:24,  1.51s/it]\u001b[A\n",
            "training set:   6%|▌         | 6/101 [00:09<02:24,  1.52s/it]\u001b[A\n",
            "training set:   7%|▋         | 7/101 [00:10<02:23,  1.53s/it]\u001b[A\n",
            "training set:   8%|▊         | 8/101 [00:12<02:22,  1.53s/it]\u001b[A\n",
            "training set:   9%|▉         | 9/101 [00:13<02:21,  1.53s/it]\u001b[A\n",
            "training set:  10%|▉         | 10/101 [00:15<02:19,  1.53s/it]\u001b[A\n",
            "training set:  11%|█         | 11/101 [00:16<02:17,  1.53s/it]\u001b[A\n",
            "training set:  12%|█▏        | 12/101 [00:18<02:15,  1.52s/it]\u001b[A\n",
            "training set:  13%|█▎        | 13/101 [00:19<02:13,  1.51s/it]\u001b[A\n",
            "training set:  14%|█▍        | 14/101 [00:21<02:10,  1.50s/it]\u001b[A\n",
            "training set:  15%|█▍        | 15/101 [00:22<02:09,  1.50s/it]\u001b[A\n",
            "training set:  16%|█▌        | 16/101 [00:24<02:07,  1.50s/it]\u001b[A\n",
            "training set:  17%|█▋        | 17/101 [00:25<02:05,  1.50s/it]\u001b[A\n",
            "training set:  18%|█▊        | 18/101 [00:27<02:04,  1.50s/it]\u001b[A\n",
            "training set:  19%|█▉        | 19/101 [00:28<02:03,  1.51s/it]\u001b[A\n",
            "training set:  20%|█▉        | 20/101 [00:30<02:02,  1.51s/it]\u001b[A\n",
            "training set:  21%|██        | 21/101 [00:31<02:01,  1.52s/it]\u001b[A\n",
            "training set:  22%|██▏       | 22/101 [00:33<01:59,  1.52s/it]\u001b[A\n",
            "training set:  23%|██▎       | 23/101 [00:34<01:57,  1.51s/it]\u001b[A\n",
            "training set:  24%|██▍       | 24/101 [00:36<01:56,  1.51s/it]\u001b[A\n",
            "training set:  25%|██▍       | 25/101 [00:37<01:54,  1.51s/it]\u001b[A\n",
            "training set:  26%|██▌       | 26/101 [00:39<01:53,  1.51s/it]\u001b[A\n",
            "training set:  27%|██▋       | 27/101 [00:40<01:51,  1.50s/it]\u001b[A\n",
            "training set:  28%|██▊       | 28/101 [00:42<01:49,  1.50s/it]\u001b[A\n",
            "training set:  29%|██▊       | 29/101 [00:43<01:48,  1.50s/it]\u001b[A\n",
            "training set:  30%|██▉       | 30/101 [00:45<01:46,  1.50s/it]\u001b[A\n",
            "training set:  31%|███       | 31/101 [00:46<01:45,  1.51s/it]\u001b[A\n",
            "training set:  32%|███▏      | 32/101 [00:48<01:44,  1.51s/it]\u001b[A\n",
            "training set:  33%|███▎      | 33/101 [00:49<01:43,  1.52s/it]\u001b[A\n",
            "training set:  34%|███▎      | 34/101 [00:51<01:42,  1.52s/it]\u001b[A\n",
            "training set:  35%|███▍      | 35/101 [00:52<01:40,  1.52s/it]\u001b[A\n",
            "training set:  36%|███▌      | 36/101 [00:54<01:38,  1.51s/it]\u001b[A\n",
            "training set:  37%|███▋      | 37/101 [00:55<01:36,  1.50s/it]\u001b[A\n",
            "training set:  38%|███▊      | 38/101 [00:57<01:34,  1.50s/it]\u001b[A\n",
            "training set:  39%|███▊      | 39/101 [00:58<01:33,  1.50s/it]\u001b[A\n",
            "training set:  40%|███▉      | 40/101 [01:00<01:31,  1.50s/it]\u001b[A\n",
            "training set:  41%|████      | 41/101 [01:01<01:30,  1.50s/it]\u001b[A\n",
            "training set:  42%|████▏     | 42/101 [01:03<01:28,  1.50s/it]\u001b[A\n",
            "training set:  43%|████▎     | 43/101 [01:04<01:26,  1.50s/it]\u001b[A\n",
            "training set:  44%|████▎     | 44/101 [01:06<01:25,  1.50s/it]\u001b[A\n",
            "training set:  45%|████▍     | 45/101 [01:07<01:24,  1.51s/it]\u001b[A\n",
            "training set:  46%|████▌     | 46/101 [01:09<01:22,  1.51s/it]\u001b[A\n",
            "training set:  47%|████▋     | 47/101 [01:10<01:21,  1.51s/it]\u001b[A\n",
            "training set:  48%|████▊     | 48/101 [01:12<01:19,  1.50s/it]\u001b[A\n",
            "training set:  49%|████▊     | 49/101 [01:14<01:18,  1.51s/it]\u001b[A\n",
            "training set:  50%|████▉     | 50/101 [01:15<01:17,  1.51s/it]\u001b[A\n",
            "training set:  50%|█████     | 51/101 [01:17<01:15,  1.51s/it]\u001b[A\n",
            "training set:  51%|█████▏    | 52/101 [01:18<01:13,  1.51s/it]\u001b[A\n",
            "training set:  52%|█████▏    | 53/101 [01:20<01:12,  1.50s/it]\u001b[A\n",
            "training set:  53%|█████▎    | 54/101 [01:21<01:10,  1.50s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 55/101 [01:23<01:09,  1.50s/it]\u001b[A\n",
            "training set:  55%|█████▌    | 56/101 [01:24<01:07,  1.50s/it]\u001b[A\n",
            "training set:  56%|█████▋    | 57/101 [01:26<01:06,  1.51s/it]\u001b[A\n",
            "training set:  57%|█████▋    | 58/101 [01:27<01:05,  1.51s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 59/101 [01:29<01:03,  1.52s/it]\u001b[A\n",
            "training set:  59%|█████▉    | 60/101 [01:30<01:02,  1.52s/it]\u001b[A\n",
            "training set:  60%|██████    | 61/101 [01:32<01:00,  1.51s/it]\u001b[A\n",
            "training set:  61%|██████▏   | 62/101 [01:33<00:59,  1.51s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 63/101 [01:35<00:57,  1.51s/it]\u001b[A\n",
            "training set:  63%|██████▎   | 64/101 [01:36<00:55,  1.50s/it]\u001b[A\n",
            "training set:  64%|██████▍   | 65/101 [01:38<00:54,  1.50s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 66/101 [01:39<00:52,  1.50s/it]\u001b[A\n",
            "training set:  66%|██████▋   | 67/101 [01:41<00:50,  1.50s/it]\u001b[A\n",
            "training set:  67%|██████▋   | 68/101 [01:42<00:49,  1.50s/it]\u001b[A\n",
            "training set:  68%|██████▊   | 69/101 [01:44<00:48,  1.51s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 70/101 [01:45<00:46,  1.50s/it]\u001b[A\n",
            "training set:  70%|███████   | 71/101 [01:47<00:45,  1.51s/it]\u001b[A\n",
            "training set:  71%|███████▏  | 72/101 [01:48<00:44,  1.52s/it]\u001b[A\n",
            "training set:  72%|███████▏  | 73/101 [01:50<00:42,  1.52s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 74/101 [01:51<00:40,  1.52s/it]\u001b[A\n",
            "training set:  74%|███████▍  | 75/101 [01:53<00:39,  1.52s/it]\u001b[A\n",
            "training set:  75%|███████▌  | 76/101 [01:54<00:37,  1.51s/it]\u001b[A\n",
            "training set:  76%|███████▌  | 77/101 [01:56<00:36,  1.51s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 78/101 [01:57<00:34,  1.51s/it]\u001b[A\n",
            "training set:  78%|███████▊  | 79/101 [01:59<00:33,  1.50s/it]\u001b[A\n",
            "training set:  79%|███████▉  | 80/101 [02:00<00:31,  1.50s/it]\u001b[A\n",
            "training set:  80%|████████  | 81/101 [02:02<00:29,  1.50s/it]\u001b[A\n",
            "training set:  81%|████████  | 82/101 [02:03<00:28,  1.50s/it]\u001b[A\n",
            "training set:  82%|████████▏ | 83/101 [02:05<00:27,  1.51s/it]\u001b[A\n",
            "training set:  83%|████████▎ | 84/101 [02:06<00:25,  1.51s/it]\u001b[A\n",
            "training set:  84%|████████▍ | 85/101 [02:08<00:24,  1.51s/it]\u001b[A\n",
            "training set:  85%|████████▌ | 86/101 [02:09<00:22,  1.52s/it]\u001b[A\n",
            "training set:  86%|████████▌ | 87/101 [02:11<00:21,  1.52s/it]\u001b[A\n",
            "training set:  87%|████████▋ | 88/101 [02:12<00:19,  1.52s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 89/101 [02:14<00:18,  1.51s/it]\u001b[A\n",
            "training set:  89%|████████▉ | 90/101 [02:15<00:16,  1.51s/it]\u001b[A\n",
            "training set:  90%|█████████ | 91/101 [02:17<00:15,  1.50s/it]\u001b[A\n",
            "training set:  91%|█████████ | 92/101 [02:18<00:13,  1.50s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 93/101 [02:20<00:11,  1.49s/it]\u001b[A\n",
            "training set:  93%|█████████▎| 94/101 [02:21<00:10,  1.50s/it]\u001b[A\n",
            "training set:  94%|█████████▍| 95/101 [02:23<00:09,  1.51s/it]\u001b[A\n",
            "training set:  95%|█████████▌| 96/101 [02:24<00:07,  1.51s/it]\u001b[A\n",
            "training set:  96%|█████████▌| 97/101 [02:26<00:06,  1.51s/it]\u001b[A\n",
            "training set:  97%|█████████▋| 98/101 [02:27<00:04,  1.52s/it]\u001b[A\n",
            "training set:  98%|█████████▊| 99/101 [02:29<00:03,  1.52s/it]\u001b[A\n",
            "training set:  99%|█████████▉| 100/101 [02:30<00:01,  1.52s/it]\u001b[A\n",
            "training set: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n",
            "\n",
            "dev set:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   8%|▊         | 1/12 [00:00<00:05,  2.00it/s]\u001b[A\n",
            "dev set:  17%|█▋        | 2/12 [00:01<00:05,  1.95it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 3/12 [00:01<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 4/12 [00:02<00:04,  1.94it/s]\u001b[A\n",
            "dev set:  42%|████▏     | 5/12 [00:02<00:03,  1.94it/s]\u001b[A\n",
            "dev set:  50%|█████     | 6/12 [00:03<00:03,  1.93it/s]\u001b[A\n",
            "dev set:  58%|█████▊    | 7/12 [00:03<00:02,  1.93it/s]\u001b[A\n",
            "dev set:  67%|██████▋   | 8/12 [00:04<00:02,  1.93it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 9/12 [00:04<00:01,  1.93it/s]\u001b[A\n",
            "dev set:  83%|████████▎ | 10/12 [00:05<00:01,  1.92it/s]\u001b[A\n",
            "dev set: 100%|██████████| 12/12 [00:05<00:00,  2.08it/s]\n",
            "\n",
            "dev set:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:   4%|▎         | 1/28 [00:00<00:13,  1.94it/s]\u001b[A\n",
            "dev set:   7%|▋         | 2/28 [00:01<00:13,  1.93it/s]\u001b[A\n",
            "dev set:  11%|█         | 3/28 [00:01<00:12,  1.93it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 4/28 [00:02<00:12,  1.94it/s]\u001b[A\n",
            "dev set:  18%|█▊        | 5/28 [00:02<00:11,  1.94it/s]\u001b[A\n",
            "dev set:  21%|██▏       | 6/28 [00:03<00:11,  1.95it/s]\u001b[A\n",
            "dev set:  25%|██▌       | 7/28 [00:03<00:10,  1.94it/s]\u001b[A\n",
            "dev set:  29%|██▊       | 8/28 [00:04<00:10,  1.94it/s]\u001b[A\n",
            "dev set:  32%|███▏      | 9/28 [00:04<00:09,  1.93it/s]\u001b[A\n",
            "dev set:  36%|███▌      | 10/28 [00:05<00:09,  1.91it/s]\u001b[A\n",
            "dev set:  39%|███▉      | 11/28 [00:05<00:08,  1.90it/s]\u001b[A\n",
            "dev set:  43%|████▎     | 12/28 [00:06<00:08,  1.89it/s]\u001b[A\n",
            "dev set:  46%|████▋     | 13/28 [00:06<00:07,  1.89it/s]\u001b[A\n",
            "dev set:  50%|█████     | 14/28 [00:07<00:07,  1.88it/s]\u001b[A\n",
            "dev set:  54%|█████▎    | 15/28 [00:07<00:06,  1.86it/s]\u001b[A\n",
            "dev set:  57%|█████▋    | 16/28 [00:08<00:06,  1.87it/s]\u001b[A\n",
            "dev set:  61%|██████    | 17/28 [00:08<00:05,  1.86it/s]\u001b[A\n",
            "dev set:  64%|██████▍   | 18/28 [00:09<00:05,  1.85it/s]\u001b[A\n",
            "dev set:  68%|██████▊   | 19/28 [00:10<00:04,  1.84it/s]\u001b[A\n",
            "dev set:  71%|███████▏  | 20/28 [00:10<00:04,  1.85it/s]\u001b[A\n",
            "dev set:  75%|███████▌  | 21/28 [00:11<00:03,  1.85it/s]\u001b[A\n",
            "dev set:  79%|███████▊  | 22/28 [00:11<00:03,  1.86it/s]\u001b[A\n",
            "dev set:  82%|████████▏ | 23/28 [00:12<00:02,  1.88it/s]\u001b[A\n",
            "dev set:  86%|████████▌ | 24/28 [00:12<00:02,  1.87it/s]\u001b[A\n",
            "dev set:  89%|████████▉ | 25/28 [00:13<00:01,  1.87it/s]\u001b[A\n",
            "dev set:  93%|█████████▎| 26/28 [00:13<00:01,  1.88it/s]\u001b[A\n",
            "dev set:  96%|█████████▋| 27/28 [00:14<00:00,  1.87it/s]\u001b[A\n",
            "dev set: 100%|██████████| 28/28 [00:14<00:00,  1.90it/s]\n",
            "100%|██████████| 5/5 [14:18<00:00, 171.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 1.7343 Validation loss: 1.7509 Test loss: 1.7443\n",
            "Train accuracy: 0.2210 Validation accuracy: 0.2416 Test accuracy: 0.2404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss, label='training loss')\n",
        "plt.plot(validation_loss, label='validation loss')\n",
        "plt.plot(test_loss, label='test loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0,4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iec8xbPLJheR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "cf8c82c8-68cf-4e75-97ed-79895766eaf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc, label='training accuracy')\n",
        "plt.plot(validation_acc, label='validation accuracy')\n",
        "plt.plot(test_acc, label='test accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylim(0,2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_w9lnCY3JiPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "65e4fa38-e5e4-41dd-c8de-bb7cb6f4c410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}