{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_9x1m3YC3RF",
        "outputId": "33c96774-21a3-4986-a60f-b95cde7f00de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5jGMRPJ1E1e",
        "outputId": "52032414-1f8a-4ab2-a352-cecc144c8de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Dataset\n",
        "# repository https://github.com/iresiragusa/NLP/tree/main\n",
        "# https://www.kaggle.com/datasets/yufengdev/bbc-fulltext-and-category?select=bbc-text.csv\n",
        "# scarichiamo il dataset e lo carichiamo su COLAB\n",
        "\n",
        "root = \"/content/gdrive/MyDrive/Colab Notebooks/torch/\"\n",
        "df = pd.read_csv(root+\"data/BBC-text/bbc-text.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# associo ad ogni categoria un indice, così ho delle label numeriche\n",
        "labels_dict = {\n",
        "    'business': 0,\n",
        "    'politics': 1,\n",
        "    'tech': 2,\n",
        "    'sport': 3,\n",
        "    'entertainment': 4\n",
        "}\n",
        "\n",
        "df['labels'] = df.apply(lambda row: labels_dict[row.category], axis = 1)"
      ],
      "metadata": {
        "id": "ystNFP_lfgwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creo train, val e test\n",
        "\n",
        "(x_train, x_test, y_train, y_test) = train_test_split(df['text'], df['labels'], test_size=0.2, random_state=17)\n",
        "\n",
        "(x_train, x_val, y_train, y_val) = train_test_split( x_train, y_train, test_size=0.1, random_state=17)"
      ],
      "metadata": {
        "id": "s16PrHdD1bs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"roberta-base\"\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, config=config)"
      ],
      "metadata": {
        "id": "_H4RzL8u1kHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4178d1e-9ee3-4626-d680-bc30f3b1891f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# come funziona il tokenizzatore di BERT\n",
        "\n",
        "s = 'The quick brown fox, jumps over: the lazy dog.'\n",
        "print(len(s))\n",
        "print(s)\n",
        "print(len(tokenizer.tokenize(s)))\n",
        "print(tokenizer.tokenize(s)) # è la lista delle parole tokenizzate\n",
        "\n",
        "tensors = True\n",
        "\n",
        "# tk = tokenizer(s, add_special_tokens=True, return_tensors=\"pt\")\n",
        "# restituisce un dizionario con i seguenti campi\n",
        "# input_ids -> tokens numerici\n",
        "# token_type_ids -> se 0 è la prima frase, se è 1 è la  seconda [CLS] sentence 1 [SEP] sentence 2\n",
        "# attention_mask -> 1 se c'è un token in posizione, si vede meglio sotto quando passo una lista di frasi da processare\n",
        "\n",
        "if tensors:\n",
        "    tk = tokenizer(s, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    print(tk['input_ids'].shape)\n",
        "    print(type(tk['input_ids']))\n",
        "    print(tk['input_ids'])\n",
        "    print('----')\n",
        "    print(tk['attention_mask'].shape)\n",
        "    print(type(tk['attention_mask']))\n",
        "    print(tk['attention_mask'])\n",
        "else:\n",
        "    tk = tokenizer(s, add_special_tokens=False)\n",
        "    print(len(tk['input_ids']))\n",
        "    print(type(tk['input_ids']))\n",
        "    print(tk['input_ids'])\n",
        "    print('----')\n",
        "    print(len(tk['attention_mask']))\n",
        "    print(type(tk['attention_mask']))\n",
        "    print(tk['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdO7Gv_bECSA",
        "outputId": "bfe650b7-bda4-428a-b4ba-b14402e4e9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "The quick brown fox, jumps over: the lazy dog.\n",
            "12\n",
            "['the', 'quick', 'brown', 'fox', ',', 'jumps', 'over', ':', 'the', 'lazy', 'dog', '.']\n",
            "torch.Size([1, 14])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[  101,  1996,  4248,  2829,  4419,  1010, 14523,  2058,  1024,  1996,\n",
            "         13971,  3899,  1012,   102]])\n",
            "----\n",
            "torch.Size([1, 14])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "print(tokenizer.tokenize(s))\n",
        "if tensors:\n",
        "    tk = tokenizer(s, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    print(tk['input_ids'].shape)\n",
        "    print(type(tk['input_ids']))\n",
        "    print(tk['input_ids'])\n",
        "    print('----')\n",
        "    print(tk['attention_mask'].shape)\n",
        "    print(type(tk['attention_mask']))\n",
        "    print(tk['attention_mask'])\n",
        "else:\n",
        "    tk = tokenizer(s, add_special_tokens=False)\n",
        "    print(len(tk['input_ids']))\n",
        "    print(type(tk['input_ids']))\n",
        "    print(tk['input_ids'])\n",
        "    print('----')\n",
        "    print(len(tk['attention_mask']))\n",
        "    print(type(tk['attention_mask']))\n",
        "    print(tk['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TTKjJZmC7Zd",
        "outputId": "0990c603-60a3-4612-a7b2-fb14763a4a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'quick', 'brown', 'fox', ',', 'jumps', 'over', ':', 'the', 'lazy', 'dog', '.']\n",
            "torch.Size([1, 14])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[  101,  1996,  4248,  2829,  4419,  1010, 14523,  2058,  1024,  1996,\n",
            "         13971,  3899,  1012,   102]])\n",
            "----\n",
            "torch.Size([1, 14])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = ['The quick brown fox',\n",
        "     'jumps over: the lazy dog.',\n",
        "     'The quick brown fox, jumps over: the lazy dog.']\n",
        "\n",
        "tk = tokenizer(s, add_special_tokens=True, return_tensors=\"pt\", padding=True)\n",
        "print(tk['input_ids'].shape)\n",
        "print(type(tk['input_ids']))\n",
        "print(tk['input_ids'])\n",
        "print('----')\n",
        "print(tk['attention_mask'].shape)\n",
        "print(type(tk['attention_mask']))\n",
        "print(tk['attention_mask'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSgOHdIcs9Na",
        "outputId": "dea937da-fc05-439c-c7e1-283dc39821bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 14])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[    0,   133,  2119,  6219, 23602,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [    0,   267, 11768,    81,    35,     5, 22414,  2335,     4,     2,\n",
            "             1,     1,     1,     1],\n",
            "        [    0,   133,  2119,  6219, 23602,     6, 13855,    81,    35,     5,\n",
            "         22414,  2335,     4,     2]])\n",
            "----\n",
            "torch.Size([3, 14])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**tk)\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(last_hidden_states.shape)\n",
        "# (n, l, d)\n",
        "    # n batch size\n",
        "    # l max len (padding value)\n",
        "    # d emb size\n",
        "print(last_hidden_states)\n",
        "#print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGk9palVFteL",
        "outputId": "b4744a2a-c5b4-46f1-93be-4947b6865ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 14, 768])\n",
            "tensor([[[-0.0633,  0.0878,  0.0058,  ..., -0.0603, -0.0532,  0.0037],\n",
            "         [-0.1798, -0.0565,  0.2604,  ...,  0.0176,  0.0379,  0.1828],\n",
            "         [-0.1793,  0.1984,  0.0795,  ..., -0.4205,  0.0426,  0.1241],\n",
            "         ...,\n",
            "         [-0.0439,  0.0719,  0.1323,  ...,  0.0635, -0.0428,  0.0897],\n",
            "         [-0.0439,  0.0719,  0.1323,  ...,  0.0635, -0.0428,  0.0897],\n",
            "         [-0.0439,  0.0719,  0.1323,  ...,  0.0635, -0.0428,  0.0897]],\n",
            "\n",
            "        [[-0.1462,  0.0946, -0.0063,  ..., -0.1004, -0.0628, -0.0156],\n",
            "         [ 0.0551, -0.0620, -0.0420,  ..., -0.2772, -0.0434,  0.0910],\n",
            "         [-0.0131,  0.1782,  0.0057,  ..., -0.4606, -0.0345,  0.0100],\n",
            "         ...,\n",
            "         [-0.0063, -0.0916,  0.0834,  ..., -0.0252, -0.0698,  0.0268],\n",
            "         [-0.0063, -0.0916,  0.0834,  ..., -0.0252, -0.0698,  0.0268],\n",
            "         [-0.0063, -0.0916,  0.0834,  ..., -0.0252, -0.0698,  0.0268]],\n",
            "\n",
            "        [[-0.1371,  0.0902, -0.0104,  ..., -0.0628, -0.0530,  0.0093],\n",
            "         [-0.1730, -0.0013,  0.0470,  ...,  0.0945, -0.0013,  0.1585],\n",
            "         [-0.0590,  0.1471, -0.0120,  ..., -0.2976, -0.0327,  0.1491],\n",
            "         ...,\n",
            "         [-0.0096,  0.2085,  0.0613,  ..., -0.1549, -0.0044,  0.1903],\n",
            "         [-0.1360,  0.0879, -0.0339,  ..., -0.0914, -0.0577, -0.0015],\n",
            "         [-0.0598,  0.1404,  0.1136,  ...,  0.2383, -0.1246,  0.1007]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "model = \"bert-base-uncased\"\n",
        "task = \"feature-extraction\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "\n",
        "text = 'The quick brown fox, jumps over: the lazy dog.'\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "\n",
        "\n",
        "feature_extractor = pipeline(task = task, model=model, tokenizer=tokenizer)\n",
        "result = feature_extractor(text, return_tensors=True)\n",
        "# con pipeline di hugging face fa la stessa cosa, estrae i cls token"
      ],
      "metadata": {
        "id": "6ezG6qR16JAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'The quick brown fox, jumps over: the lazy dog.'\n",
        "tk = tokenizer(s, add_special_tokens=True, return_tensors=\"pt\")\n",
        "outputs = model(**tk)\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(last_hidden_states.shape)\n",
        "# (n, l, d)\n",
        "    # n batch size\n",
        "    # l max len (padding value)\n",
        "    # d emb size\n",
        "print(last_hidden_states)\n",
        "#print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xkkg1K2u11P",
        "outputId": "a28aba84-f331-4d02-d21e-37e57a9aeac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 14, 768])\n",
            "tensor([[[-0.5449, -0.0099, -0.3117,  ..., -0.2595,  0.4935,  0.5315],\n",
            "         [-0.4142, -0.4263, -0.3243,  ..., -0.0633,  1.3985, -0.1521],\n",
            "         [-0.5988, -0.4446,  0.6228,  ..., -0.0395,  0.3968, -0.1668],\n",
            "         ...,\n",
            "         [ 0.2650,  0.2589,  0.1067,  ..., -0.2739,  0.3995,  0.4982],\n",
            "         [-0.9317, -0.5384, -0.3776,  ...,  0.5825,  0.4579, -0.5600],\n",
            "         [ 0.6834,  0.2844, -0.5239,  ...,  0.0819, -0.5736, -0.3002]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_states == result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOK-89FHssg",
        "outputId": "f4e9f11d-1d4c-4f9f-b868-e2de217aad53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         ...,\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True],\n",
              "         [True, True, True,  ..., True, True, True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# rimozione stopword e creazione dataset\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, y, stopwords):\n",
        "\n",
        "        if stopwords:\n",
        "            tokens_litt = [nltk.word_tokenize(text, language='english') for text\n",
        "                           in list(x)]\n",
        "            text_clean = []\n",
        "            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n",
        "                text_clean.append(' '.join([w for w in sentence if not w.lower()\n",
        "                in nltk.corpus.stopwords.words(\"english\")]))\n",
        "        else:\n",
        "            tokens_litt = [nltk.word_tokenize(text, language='english') for text\n",
        "                           in list(x)]\n",
        "            text_clean = []\n",
        "            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n",
        "                #sentence_clean = ' '.join([w.lower() for w in sentence])\n",
        "                #text_clean.append(sentence_clean)\n",
        "                text_clean.append(' '.join([w.lower() for w in sentence]))\n",
        "            # ogni token è separato dall'altro con uno spazio\n",
        "        self.texts = [text for text in text_clean]\n",
        "        self.labels = [torch.tensor(label) for label in y]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "        return batch_texts, batch_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlYWKSjDeQi8",
        "outputId": "82ff1091-8423-49c7-d4c8-25a229460e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    \"epochs\": 5,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    #\"stopwords\": True,\n",
        "    \"stopwords\": False,\n",
        "    \"h_dim\": 768,\n",
        "    \"patience\": 5,\n",
        "    \"min_delta\": 0.01,\n",
        "    #\"language_model\": \"bert-base-uncased\"\n",
        "    \"language_model\": \"roberta-base\"\n",
        "}"
      ],
      "metadata": {
        "id": "TdXojbqsejFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creo i dataset\n",
        "\n",
        "train_dataset = Dataset(x_train, y_train, hyperparameters[\"stopwords\"])\n",
        "val_dataset = Dataset(x_val, y_val, hyperparameters[\"stopwords\"])\n",
        "test_dataset = Dataset(x_test, y_test, hyperparameters[\"stopwords\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbuEU9Xzevlz",
        "outputId": "3d21efd8-a70f-4893-c7c6-76734a41fbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing ... : 100%|██████████| 1602/1602 [00:00<00:00, 12170.42it/s]\n",
            "Tokenizing ... : 100%|██████████| 178/178 [00:00<00:00, 9817.30it/s]\n",
            "Tokenizing ... : 100%|██████████| 445/445 [00:00<00:00, 11895.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierDeep(nn.Module):\n",
        "\n",
        "    def __init__(self, labels, hdim, dropout):\n",
        "        super(ClassifierDeep, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hdim, hdim),\n",
        "            nn.BatchNorm1d(hdim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hdim, labels),\n",
        "            )\n",
        "\n",
        "    def forward(self, input_texts):\n",
        "        return self.classifier(input_texts)"
      ],
      "metadata": {
        "id": "qrQ38Hr5a_xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0):\n",
        "\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta              # valore minimo di decrescita della loss di validazione all'epoca corrente\n",
        "                                                # per asserire che c'è un miglioramenti della loss\n",
        "        self.counter = 0                        # contatore delle epoche di pazienza\n",
        "        self.early_stop = False                 # flag di early stop\n",
        "        self.min_validation_loss = torch.inf    # valore corrente ottimo della loss di validazione\n",
        "\n",
        "    def __call__(self, validation_loss):\n",
        "        # chiamata in forma funzionale dell'oggetto di classe EarlySopping\n",
        "        if (validation_loss + self.min_delta) >= self.min_validation_loss:  # la loss di validazione non decresce\n",
        "            self.counter += 1                                               # incrementiamo il contatore delle epoche di pazienza\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                print(\"Early stop!\")\n",
        "        else:                                                               # c'è un miglioramento della loss:\n",
        "            self.min_validation_loss = validation_loss                      # consideriamo la loss corrente\n",
        "                                                                            # come nuova loss ottimale\n",
        "            self.counter = 0                                                # e azzeriamo il contatore di pazienza"
      ],
      "metadata": {
        "id": "YeLXqnCIgc9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_embeddings(input_id_text, attention_mask, lm_model):\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = lm_model(input_id_text,\n",
        "                            attention_mask=attention_mask).last_hidden_state\n",
        "        last_hidden_states = last_hidden_states[:,0,:]\n",
        "    return last_hidden_states"
      ],
      "metadata": {
        "id": "kOpbdbRHsOpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, dataloader, tokenizer, lm_model, loss, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch_texts, batch_labels in tqdm(dataloader, desc='training set'):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        tokens = tokenizer(list(batch_texts), add_special_tokens=True,\n",
        "                return_tensors='pt', padding='max_length',\n",
        "                max_length = 512, truncation=True)\n",
        "        input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n",
        "        mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        embeddings_texts = gen_embeddings(input_id_texts, mask_texts, lm_model)\n",
        "        output = model(embeddings_texts)\n",
        "\n",
        "        # la loss è una CrossEntropyLoss, al suo interno ha la logsoftmax + negative log likelihood loss\n",
        "        batch_loss = loss(output, batch_labels)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += batch_loss.item()\n",
        "\n",
        "        # per calcolare l'accuracy devo generare le predizioni applicando manualmente la logsoftmax\n",
        "        softmax = nn.LogSoftmax(dim=1)\n",
        "        epoch_acc += (softmax(output).argmax(dim=1) == batch_labels).sum().item()\n",
        "\n",
        "        batch_labels = batch_labels.detach().cpu()\n",
        "        input_id_texts = input_id_texts.detach().cpu()\n",
        "        mask_texts = mask_texts.detach().cpu()\n",
        "        output = output.detach().cpu()\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc"
      ],
      "metadata": {
        "id": "eRwTy5yVgoCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model, dataloader, tokenizer, lm_model, loss, device):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_texts, batch_labels, in tqdm(dataloader, desc='dev set'):\n",
        "\n",
        "            tokens = tokenizer(list(batch_texts), add_special_tokens=True, return_tensors='pt', padding='max_length', max_length = 512, truncation=True)\n",
        "            input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n",
        "            mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            embeddings_texts = gen_embeddings(input_id_texts, mask_texts, lm_model)\n",
        "            output = model(embeddings_texts)\n",
        "\n",
        "            batch_loss = loss(output, batch_labels)\n",
        "            epoch_loss += batch_loss.item()\n",
        "\n",
        "            softmax = nn.LogSoftmax(dim=1)\n",
        "            epoch_acc += (softmax(output).argmax(dim=1) == batch_labels).sum().item()\n",
        "\n",
        "            batch_labels = batch_labels.detach().cpu()\n",
        "            input_id_texts = input_id_texts.detach().cpu()\n",
        "            mask_texts = mask_texts.detach().cpu()\n",
        "            output = output.detach().cpu()\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc"
      ],
      "metadata": {
        "id": "Jo7jZ2PDuRAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(model, epochs, optimizer, device, train_data, test_data,\n",
        "               batch_size, language_model, train_loss_fn, test_loss_fn=None,\n",
        "               early_stopping=None, val_data=None, scheduler=None):\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    # check sulle funzioni di loss\n",
        "    if test_loss_fn == None:\n",
        "        test_loss_fn = train_loss_fn\n",
        "\n",
        "    # liste dei valori di loss e accuracy epoca per epoca per il plot\n",
        "    train_loss = []\n",
        "    validation_loss = []\n",
        "    test_loss = []\n",
        "\n",
        "    train_acc = []\n",
        "    validation_acc = []\n",
        "    test_acc = []\n",
        "\n",
        "    config = AutoConfig.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    lm_model = AutoModel.from_pretrained(model_name, config=config).to(device)\n",
        "\n",
        "    # Ciclo di addestramento con early stopping\n",
        "    for epoch in tqdm(range(1,epochs+1)):\n",
        "        epoch_train_loss, epoch_train_acc = train_loop(model,\n",
        "                    train_dataloader, tokenizer, lm_model, train_loss_fn, optimizer, device)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc/len(train_data))\n",
        "\n",
        "        # validation se è presente la callback di early stopping\n",
        "        if early_stopping != None:\n",
        "                epoch_validate_loss, epoch_validate_acc = test_loop(model, val_dataloader, tokenizer, lm_model, test_loss_fn, device)\n",
        "                validation_loss.append(epoch_validate_loss)\n",
        "                validation_acc.append(epoch_validate_acc/len(val_data))\n",
        "\n",
        "        # test\n",
        "        epoch_test_loss, epoch_test_acc,= test_loop(model, test_dataloader, tokenizer, lm_model, test_loss_fn, device)\n",
        "        test_loss.append(epoch_test_loss)\n",
        "        test_acc.append(epoch_test_acc/len(test_data))\n",
        "\n",
        "        val_loss_str = f'Validation loss: {epoch_validate_loss:6.4f} ' if early_stopping != None else ' '\n",
        "        val_acc_str = f'Validation accuracy: {(epoch_validate_acc/len(val_data)):6.4f} ' if early_stopping != None else ' '\n",
        "        print(f\"\\nTrain loss: {epoch_train_loss:6.4f} {val_loss_str} Test loss: {epoch_test_loss:6.4f}\")\n",
        "        print(f\"Train accuracy: {(epoch_train_acc/len(train_data)):6.4f} {val_acc_str}Test accuracy: {(epoch_test_acc/len(test_data)):6.4f}\")\n",
        "\n",
        "        # early stopping\n",
        "        if early_stopping != None:\n",
        "                early_stopping(epoch_validate_loss)\n",
        "                if early_stopping.early_stop:\n",
        "                    break\n",
        "\n",
        "    return train_loss, validation_loss, test_loss, train_acc, validation_acc, test_acc"
      ],
      "metadata": {
        "id": "W_urLi5MubL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acquisiamo il device su cui effettueremo il training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "model = ClassifierDeep(len(labels_dict),\n",
        "                    hyperparameters[\"h_dim\"],\n",
        "                    hyperparameters[\"dropout\"]).to(device)\n",
        "print(model)\n",
        "\n",
        "# Calcoliamo il numero totale dei parametri del modello\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Numbero totale dei parametri: {total_params}\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"])\n",
        "# Creiamo la callback di early stopping da passare al nostro metodo di addestramento\n",
        "early_stopping = EarlyStopping(patience=hyperparameters['patience'], min_delta=hyperparameters['min_delta'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozVTHJGFvjEi",
        "outputId": "c0d03348-f0bb-4c72-9da6-1c42fd9fcc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "ClassifierDeep(\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=768, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "Numbero totale dei parametri: 595973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Routine di addestramento\n",
        "train_loss, validation_loss,test_loss, train_acc, validation_acc, test_acc = train_test(model,\n",
        "                                                hyperparameters['epochs'],\n",
        "                                                #50,\n",
        "                                                optimizer,\n",
        "                                                device,\n",
        "                                                train_dataset,\n",
        "                                                test_dataset,\n",
        "                                                hyperparameters['batch_size'],\n",
        "                                                hyperparameters['language_model'],\n",
        "                                                criterion,\n",
        "                                                criterion,\n",
        "                                                early_stopping,\n",
        "                                                val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHT4iHdawXrT",
        "outputId": "b695bdd1-7ef8-404e-aa75-f570e2c3dc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "training set:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   4%|▍         | 1/26 [00:04<01:59,  4.78s/it]\u001b[A\n",
            "training set:   8%|▊         | 2/26 [00:06<01:14,  3.10s/it]\u001b[A\n",
            "training set:  12%|█▏        | 3/26 [00:08<00:58,  2.53s/it]\u001b[A\n",
            "training set:  15%|█▌        | 4/26 [00:10<00:49,  2.25s/it]\u001b[A\n",
            "training set:  19%|█▉        | 5/26 [00:12<00:44,  2.11s/it]\u001b[A\n",
            "training set:  23%|██▎       | 6/26 [00:14<00:40,  2.01s/it]\u001b[A\n",
            "training set:  27%|██▋       | 7/26 [00:15<00:37,  1.96s/it]\u001b[A\n",
            "training set:  31%|███       | 8/26 [00:17<00:34,  1.92s/it]\u001b[A\n",
            "training set:  35%|███▍      | 9/26 [00:19<00:32,  1.93s/it]\u001b[A\n",
            "training set:  38%|███▊      | 10/26 [00:21<00:30,  1.93s/it]\u001b[A\n",
            "training set:  42%|████▏     | 11/26 [00:23<00:28,  1.93s/it]\u001b[A\n",
            "training set:  46%|████▌     | 12/26 [00:25<00:26,  1.91s/it]\u001b[A\n",
            "training set:  50%|█████     | 13/26 [00:27<00:24,  1.90s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 14/26 [00:29<00:22,  1.89s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 15/26 [00:31<00:20,  1.88s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 16/26 [00:32<00:18,  1.88s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 17/26 [00:34<00:17,  1.89s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 18/26 [00:36<00:15,  1.90s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 19/26 [00:38<00:13,  1.92s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 20/26 [00:40<00:11,  1.91s/it]\u001b[A\n",
            "training set:  81%|████████  | 21/26 [00:42<00:09,  1.94s/it]\u001b[A\n",
            "training set:  85%|████████▍ | 22/26 [00:44<00:08,  2.01s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 23/26 [00:46<00:06,  2.03s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 24/26 [00:48<00:04,  2.02s/it]\u001b[A\n",
            "training set: 100%|██████████| 26/26 [00:50<00:00,  1.96s/it]\n",
            "\n",
            "dev set:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 1/3 [00:01<00:03,  1.93s/it]\u001b[A\n",
            "dev set:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it]\u001b[A\n",
            "dev set: 100%|██████████| 3/3 [00:05<00:00,  1.78s/it]\n",
            "\n",
            "dev set:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 1/7 [00:01<00:11,  1.91s/it]\u001b[A\n",
            "dev set:  29%|██▊       | 2/7 [00:03<00:09,  1.94s/it]\u001b[A\n",
            "dev set:  43%|████▎     | 3/7 [00:05<00:07,  1.93s/it]\u001b[A\n",
            "dev set:  57%|█████▋    | 4/7 [00:07<00:05,  1.93s/it]\u001b[A\n",
            "dev set:  71%|███████▏  | 5/7 [00:09<00:03,  1.92s/it]\u001b[A\n",
            "dev set:  86%|████████▌ | 6/7 [00:11<00:01,  1.93s/it]\u001b[A\n",
            "dev set: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n",
            " 20%|██        | 1/5 [01:09<04:39, 69.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 0.2390 Validation loss: 1.0323  Test loss: 1.0141\n",
            "Train accuracy: 0.9238 Validation accuracy: 0.9494 Test accuracy: 0.9483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   4%|▍         | 1/26 [00:02<00:50,  2.01s/it]\u001b[A\n",
            "training set:   8%|▊         | 2/26 [00:03<00:47,  1.96s/it]\u001b[A\n",
            "training set:  12%|█▏        | 3/26 [00:05<00:44,  1.95s/it]\u001b[A\n",
            "training set:  15%|█▌        | 4/26 [00:07<00:42,  1.95s/it]\u001b[A\n",
            "training set:  19%|█▉        | 5/26 [00:09<00:40,  1.95s/it]\u001b[A\n",
            "training set:  23%|██▎       | 6/26 [00:11<00:38,  1.95s/it]\u001b[A\n",
            "training set:  27%|██▋       | 7/26 [00:13<00:37,  1.96s/it]\u001b[A\n",
            "training set:  31%|███       | 8/26 [00:15<00:35,  1.99s/it]\u001b[A\n",
            "training set:  35%|███▍      | 9/26 [00:17<00:34,  2.00s/it]\u001b[A\n",
            "training set:  38%|███▊      | 10/26 [00:19<00:31,  1.99s/it]\u001b[A\n",
            "training set:  42%|████▏     | 11/26 [00:21<00:29,  1.98s/it]\u001b[A\n",
            "training set:  46%|████▌     | 12/26 [00:23<00:27,  1.98s/it]\u001b[A\n",
            "training set:  50%|█████     | 13/26 [00:25<00:25,  1.98s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 14/26 [00:27<00:23,  1.98s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 15/26 [00:29<00:22,  2.01s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 16/26 [00:31<00:20,  2.03s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 17/26 [00:33<00:18,  2.06s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 18/26 [00:35<00:16,  2.04s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 19/26 [00:37<00:14,  2.03s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 20/26 [00:39<00:12,  2.03s/it]\u001b[A\n",
            "training set:  81%|████████  | 21/26 [00:41<00:10,  2.03s/it]\u001b[A\n",
            "training set:  85%|████████▍ | 22/26 [00:43<00:08,  2.03s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 23/26 [00:46<00:06,  2.04s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 24/26 [00:48<00:04,  2.05s/it]\u001b[A\n",
            "training set: 100%|██████████| 26/26 [00:50<00:00,  1.93s/it]\n",
            "\n",
            "dev set:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 1/3 [00:02<00:04,  2.01s/it]\u001b[A\n",
            "dev set:  67%|██████▋   | 2/3 [00:04<00:02,  2.01s/it]\u001b[A\n",
            "dev set: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]\n",
            "\n",
            "dev set:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 1/7 [00:01<00:11,  2.00s/it]\u001b[A\n",
            "dev set:  29%|██▊       | 2/7 [00:03<00:09,  2.00s/it]\u001b[A\n",
            "dev set:  43%|████▎     | 3/7 [00:06<00:08,  2.03s/it]\u001b[A\n",
            "dev set:  57%|█████▋    | 4/7 [00:08<00:06,  2.06s/it]\u001b[A\n",
            "dev set:  71%|███████▏  | 5/7 [00:10<00:04,  2.05s/it]\u001b[A\n",
            "dev set:  86%|████████▌ | 6/7 [00:12<00:02,  2.03s/it]\u001b[A\n",
            "dev set: 100%|██████████| 7/7 [00:14<00:00,  2.00s/it]\n",
            " 40%|████      | 2/5 [02:19<03:29, 69.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 0.2050 Validation loss: 0.2978  Test loss: 0.2737\n",
            "Train accuracy: 0.9838 Validation accuracy: 0.9494 Test accuracy: 0.9416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   4%|▍         | 1/26 [00:01<00:49,  1.96s/it]\u001b[A\n",
            "training set:   8%|▊         | 2/26 [00:03<00:47,  1.97s/it]\u001b[A\n",
            "training set:  12%|█▏        | 3/26 [00:05<00:45,  1.98s/it]\u001b[A\n",
            "training set:  15%|█▌        | 4/26 [00:07<00:44,  2.01s/it]\u001b[A\n",
            "training set:  19%|█▉        | 5/26 [00:10<00:42,  2.01s/it]\u001b[A\n",
            "training set:  23%|██▎       | 6/26 [00:12<00:40,  2.02s/it]\u001b[A\n",
            "training set:  27%|██▋       | 7/26 [00:14<00:38,  2.00s/it]\u001b[A\n",
            "training set:  31%|███       | 8/26 [00:15<00:35,  2.00s/it]\u001b[A\n",
            "training set:  35%|███▍      | 9/26 [00:18<00:35,  2.07s/it]\u001b[A\n",
            "training set:  38%|███▊      | 10/26 [00:20<00:32,  2.04s/it]\u001b[A\n",
            "training set:  42%|████▏     | 11/26 [00:22<00:30,  2.02s/it]\u001b[A\n",
            "training set:  46%|████▌     | 12/26 [00:24<00:28,  2.03s/it]\u001b[A\n",
            "training set:  50%|█████     | 13/26 [00:26<00:26,  2.05s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 14/26 [00:28<00:24,  2.05s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 15/26 [00:30<00:22,  2.02s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 16/26 [00:32<00:20,  2.01s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 17/26 [00:34<00:18,  2.00s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 18/26 [00:36<00:15,  2.00s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 19/26 [00:38<00:13,  2.00s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 20/26 [00:40<00:12,  2.01s/it]\u001b[A\n",
            "training set:  81%|████████  | 21/26 [00:42<00:10,  2.03s/it]\u001b[A\n",
            "training set:  85%|████████▍ | 22/26 [00:44<00:08,  2.03s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 23/26 [00:46<00:06,  2.02s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 24/26 [00:48<00:04,  2.01s/it]\u001b[A\n",
            "training set: 100%|██████████| 26/26 [00:50<00:00,  1.94s/it]\n",
            "\n",
            "dev set:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 1/3 [00:01<00:03,  1.98s/it]\u001b[A\n",
            "dev set:  67%|██████▋   | 2/3 [00:03<00:01,  2.00s/it]\u001b[A\n",
            "dev set: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]\n",
            "\n",
            "dev set:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 1/7 [00:02<00:12,  2.06s/it]\u001b[A\n",
            "dev set:  29%|██▊       | 2/7 [00:04<00:10,  2.07s/it]\u001b[A\n",
            "dev set:  43%|████▎     | 3/7 [00:06<00:08,  2.04s/it]\u001b[A\n",
            "dev set:  57%|█████▋    | 4/7 [00:08<00:06,  2.03s/it]\u001b[A\n",
            "dev set:  71%|███████▏  | 5/7 [00:10<00:04,  2.02s/it]\u001b[A\n",
            "dev set:  86%|████████▌ | 6/7 [00:12<00:02,  2.01s/it]\u001b[A\n",
            "dev set: 100%|██████████| 7/7 [00:13<00:00,  2.00s/it]\n",
            " 60%|██████    | 3/5 [03:29<02:19, 69.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 0.0307 Validation loss: 0.0993  Test loss: 0.0720\n",
            "Train accuracy: 0.9950 Validation accuracy: 0.9775 Test accuracy: 0.9798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   4%|▍         | 1/26 [00:02<00:50,  2.04s/it]\u001b[A\n",
            "training set:   8%|▊         | 2/26 [00:04<00:49,  2.05s/it]\u001b[A\n",
            "training set:  12%|█▏        | 3/26 [00:06<00:47,  2.06s/it]\u001b[A\n",
            "training set:  15%|█▌        | 4/26 [00:08<00:44,  2.03s/it]\u001b[A\n",
            "training set:  19%|█▉        | 5/26 [00:10<00:42,  2.01s/it]\u001b[A\n",
            "training set:  23%|██▎       | 6/26 [00:12<00:40,  2.01s/it]\u001b[A\n",
            "training set:  27%|██▋       | 7/26 [00:14<00:38,  2.00s/it]\u001b[A\n",
            "training set:  31%|███       | 8/26 [00:16<00:36,  2.00s/it]\u001b[A\n",
            "training set:  35%|███▍      | 9/26 [00:18<00:34,  2.02s/it]\u001b[A\n",
            "training set:  38%|███▊      | 10/26 [00:20<00:32,  2.02s/it]\u001b[A\n",
            "training set:  42%|████▏     | 11/26 [00:22<00:30,  2.02s/it]\u001b[A\n",
            "training set:  46%|████▌     | 12/26 [00:24<00:28,  2.01s/it]\u001b[A\n",
            "training set:  50%|█████     | 13/26 [00:26<00:26,  2.02s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 14/26 [00:28<00:24,  2.04s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 15/26 [00:30<00:22,  2.03s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 16/26 [00:32<00:20,  2.02s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 17/26 [00:34<00:18,  2.03s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 18/26 [00:36<00:16,  2.04s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 19/26 [00:38<00:14,  2.04s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 20/26 [00:40<00:12,  2.03s/it]\u001b[A\n",
            "training set:  81%|████████  | 21/26 [00:42<00:10,  2.02s/it]\u001b[A\n",
            "training set:  85%|████████▍ | 22/26 [00:44<00:08,  2.01s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 23/26 [00:46<00:06,  2.01s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 24/26 [00:48<00:04,  2.00s/it]\u001b[A\n",
            "training set: 100%|██████████| 26/26 [00:50<00:00,  1.95s/it]\n",
            "\n",
            "dev set:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 1/3 [00:02<00:04,  2.06s/it]\u001b[A\n",
            "dev set:  67%|██████▋   | 2/3 [00:04<00:02,  2.06s/it]\u001b[A\n",
            "dev set: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]\n",
            "\n",
            "dev set:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 1/7 [00:02<00:12,  2.00s/it]\u001b[A\n",
            "dev set:  29%|██▊       | 2/7 [00:04<00:10,  2.00s/it]\u001b[A\n",
            "dev set:  43%|████▎     | 3/7 [00:06<00:08,  2.01s/it]\u001b[A\n",
            "dev set:  57%|█████▋    | 4/7 [00:08<00:06,  2.01s/it]\u001b[A\n",
            "dev set:  71%|███████▏  | 5/7 [00:10<00:04,  2.02s/it]\u001b[A\n",
            "dev set:  86%|████████▌ | 6/7 [00:12<00:02,  2.03s/it]\u001b[A\n",
            "dev set: 100%|██████████| 7/7 [00:14<00:00,  2.00s/it]\n",
            " 80%|████████  | 4/5 [04:40<01:10, 70.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 0.0505 Validation loss: 0.2017  Test loss: 0.1289\n",
            "Train accuracy: 0.9969 Validation accuracy: 0.9438 Test accuracy: 0.9618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training set:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "training set:   4%|▍         | 1/26 [00:01<00:49,  2.00s/it]\u001b[A\n",
            "training set:   8%|▊         | 2/26 [00:03<00:47,  1.99s/it]\u001b[A\n",
            "training set:  12%|█▏        | 3/26 [00:05<00:45,  2.00s/it]\u001b[A\n",
            "training set:  15%|█▌        | 4/26 [00:08<00:44,  2.00s/it]\u001b[A\n",
            "training set:  19%|█▉        | 5/26 [00:10<00:42,  2.01s/it]\u001b[A\n",
            "training set:  23%|██▎       | 6/26 [00:12<00:40,  2.02s/it]\u001b[A\n",
            "training set:  27%|██▋       | 7/26 [00:14<00:38,  2.04s/it]\u001b[A\n",
            "training set:  31%|███       | 8/26 [00:16<00:36,  2.05s/it]\u001b[A\n",
            "training set:  35%|███▍      | 9/26 [00:18<00:34,  2.03s/it]\u001b[A\n",
            "training set:  38%|███▊      | 10/26 [00:20<00:32,  2.02s/it]\u001b[A\n",
            "training set:  42%|████▏     | 11/26 [00:22<00:30,  2.01s/it]\u001b[A\n",
            "training set:  46%|████▌     | 12/26 [00:24<00:28,  2.00s/it]\u001b[A\n",
            "training set:  50%|█████     | 13/26 [00:26<00:26,  2.00s/it]\u001b[A\n",
            "training set:  54%|█████▍    | 14/26 [00:28<00:24,  2.01s/it]\u001b[A\n",
            "training set:  58%|█████▊    | 15/26 [00:30<00:22,  2.02s/it]\u001b[A\n",
            "training set:  62%|██████▏   | 16/26 [00:32<00:20,  2.04s/it]\u001b[A\n",
            "training set:  65%|██████▌   | 17/26 [00:34<00:18,  2.03s/it]\u001b[A\n",
            "training set:  69%|██████▉   | 18/26 [00:36<00:16,  2.02s/it]\u001b[A\n",
            "training set:  73%|███████▎  | 19/26 [00:38<00:14,  2.01s/it]\u001b[A\n",
            "training set:  77%|███████▋  | 20/26 [00:40<00:12,  2.01s/it]\u001b[A\n",
            "training set:  81%|████████  | 21/26 [00:42<00:10,  2.01s/it]\u001b[A\n",
            "training set:  85%|████████▍ | 22/26 [00:44<00:08,  2.02s/it]\u001b[A\n",
            "training set:  88%|████████▊ | 23/26 [00:46<00:06,  2.02s/it]\u001b[A\n",
            "training set:  92%|█████████▏| 24/26 [00:48<00:04,  2.03s/it]\u001b[A\n",
            "training set: 100%|██████████| 26/26 [00:50<00:00,  1.94s/it]\n",
            "\n",
            "dev set:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  33%|███▎      | 1/3 [00:01<00:03,  1.98s/it]\u001b[A\n",
            "dev set:  67%|██████▋   | 2/3 [00:03<00:01,  1.99s/it]\u001b[A\n",
            "dev set: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
            "\n",
            "dev set:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "dev set:  14%|█▍        | 1/7 [00:01<00:11,  1.99s/it]\u001b[A\n",
            "dev set:  29%|██▊       | 2/7 [00:04<00:10,  2.05s/it]\u001b[A\n",
            "dev set:  43%|████▎     | 3/7 [00:06<00:08,  2.05s/it]\u001b[A\n",
            "dev set:  57%|█████▋    | 4/7 [00:08<00:06,  2.05s/it]\u001b[A\n",
            "dev set:  71%|███████▏  | 5/7 [00:10<00:04,  2.03s/it]\u001b[A\n",
            "dev set:  86%|████████▌ | 6/7 [00:12<00:02,  2.02s/it]\u001b[A\n",
            "dev set: 100%|██████████| 7/7 [00:14<00:00,  2.00s/it]\n",
            "100%|██████████| 5/5 [05:50<00:00, 70.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 0.0185 Validation loss: 0.1346  Test loss: 0.0949\n",
            "Train accuracy: 0.9969 Validation accuracy: 0.9551 Test accuracy: 0.9663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss, label='training loss')\n",
        "plt.plot(validation_loss, label='validation loss')\n",
        "plt.plot(test_loss, label='test loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0,4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iec8xbPLJheR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "8f21defc-353a-48cc-cc42-b8223dd3fa3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc, label='training accuracy')\n",
        "plt.plot(validation_acc, label='validation accuracy')\n",
        "plt.plot(test_acc, label='test accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0,2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_w9lnCY3JiPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "c732d536-c1a6-4f0b-d5d3-a6761fc341b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}